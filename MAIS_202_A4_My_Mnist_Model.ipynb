{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "MAIS 202 A4: My Mnist Model ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJmPHKyGxGXo",
        "outputId": "a448df6c-d6a1-4925-8121-488084001603"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.backend import repeat_elements, expand_dims, resize_images\n",
        "\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')  # TPU detection.\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "# gpus = tf.config.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#   # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
        "#   try:\n",
        "#     tf.config.set_logical_device_configuration(\n",
        "#         gpus[0],\n",
        "#         [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
        "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "#   except RuntimeError as e:\n",
        "#     # Virtual devices must be set before GPUs have been initialized\n",
        "#     print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.7.76.178:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.7.76.178:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.7.76.178:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.7.76.178:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.7.76.178:8470']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3JvmbBTsTG0",
        "outputId": "0103e065-0303-417c-f0eb-2f9a93cfb525"
      },
      "source": [
        "strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "# gpus = tf.config.list_logical_devices('GPU')\n",
        "# strategy = tf.distribute.MirroredStrategy(gpus)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGymkxgJ1oUf"
      },
      "source": [
        "Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "XiJlAdnO2isG",
        "outputId": "262fce73-c391-47b0-a2ea-01d0cf1b2765"
      },
      "source": [
        "# Kaggle API token\n",
        "\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c54475e-8c01-49ed-81fa-75f66dc52f00\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c54475e-8c01-49ed-81fa-75f66dc52f00\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e29db62d9bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' pip install -q kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJgAkQTmCpzg",
        "outputId": "983b98e6-fdcb-4cb2-9143-4afa035c80de"
      },
      "source": [
        "# Above cell was not working\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download mais202fall2021 -p /content/data/\n",
        "! cd /content/data/\n",
        "! unzip -d /content/data/ /content/data/test_images.npy\n",
        "! unzip -d /content/data/ /content/data/train_images.npy\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "test_images.npy.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_labels.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "label_int_to_str_mapping.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_images.npy.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/data/test_images.npy\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "Archive:  /content/data/test_images.npy.zip\n",
            "replace /content/data/test_images.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/data/train_images.npy\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "Archive:  /content/data/train_images.npy.zip\n",
            "replace /content/data/train_images.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_DhVChAS2-"
      },
      "source": [
        "def show_image(arr):\n",
        "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
        "    plt.imshow(two_d, interpolation='nearest')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "VcXNnZ3A4VJD",
        "outputId": "f09f08b8-0d6b-4467-e2d2-55718afd1c09"
      },
      "source": [
        "# Load training and testing data\n",
        "x_train = np.load('/content/data/train_images.npy').astype(\"float32\")/255.0\n",
        "y_train = pd.read_csv('/content/data/train_labels.csv', usecols= ['label']).to_numpy()\n",
        "x_test = np.load('/content/data/test_images.npy').astype(\"float32\")/255.0\n",
        "\n",
        "\n",
        "import skimage\n",
        "from skimage import data, io, filters, feature\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.util import random_noise\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "\n",
        "\n",
        "# x_resized_train = np.empty((x_train.shape[0], 32, 32))\n",
        "# for i in range(len(x_train)):\n",
        "#   x_resized_train[i] = resize(x_train[i], (32,32))\n",
        "\n",
        "# x_train = np.repeat((x_resized_train / x_resized_train.max()).astype(\"float32\")[..., np.newaxis], 3, -1)\n",
        "# x_test = np.repeat((x_resized_train / x_resized_train.max()).astype(\"float32\")[..., np.newaxis], 3, -1)\n",
        "print(x_train.shape)\n",
        "\n",
        "x_train = x_train.reshape((50000,28,28,1))\n",
        "x_test = x_test.reshape((x_test.shape[0],28,28,1))\n",
        "\n",
        "show_image(x_train[0])\n",
        "print(y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6]\n",
            " [4]\n",
            " [6]\n",
            " ...\n",
            " [7]\n",
            " [3]\n",
            " [2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1VO2EEB6Hut",
        "outputId": "d616e52b-d468-4e28-ecaf-6e373b2fc2d9"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seKIZU7zb3VA",
        "outputId": "c3a5b64a-2076-4714-d466-25bf0c4f86aa"
      },
      "source": [
        "print(x_train.shape)\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "print(y_train)\n",
        "print(y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 28, 28, 1)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "(50000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQAbbbn1fgwG"
      },
      "source": [
        "Model #1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ9xXwtefgYU"
      },
      "source": [
        "# Preprocess\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "def model2(): # lr 0.0001: 89.95% val | not 0.001, 0.005\n",
        "  with strategy.scope():\n",
        "    model = models.Sequential()\n",
        "    model.add(Dense(256, activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(Dense(256, activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last', input_shape=(28,28,1)))\n",
        "    # model.add(layers.GaussianNoise(0.01))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                    data_format='channels_last'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                    data_format='channels_last'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "        \n",
        "        \n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                    data_format='channels_last'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.build()\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00005, decay=1e-6), \n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
        "                  metrics=['accuracy'],\n",
        "                  steps_per_execution = 100)\n",
        "    model.summary()\n",
        "    return model\n",
        "def model3():\n",
        "  with strategy.scope():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=(28,28,1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Activation('elu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(10))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy'])\n",
        "    return model\n",
        "def model4():\n",
        "  with strategy.scope():\n",
        "    mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32,32,3), pooling='avg')\n",
        "    mobilenet.trainable = True\n",
        "\n",
        "    model = models.Sequential()\n",
        "    # model.add(layers.Lambda(lambda image: resize_images(x=image, height_factor=2, width_factor=2, data_format='channels_last'), input_shape=(28,28,3)))\n",
        "    model.add(mobilenet)\n",
        "    # model.add(Dropout(0.5))\n",
        "\n",
        "    # model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))   \n",
        "    model.add(Dropout(0.25))\n",
        "    # model.add(Dense(256, activation='relu'))\n",
        "    # model.add(Dropout(0.25))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.build()\n",
        "    model.compile(optimizer=\"adam\", \n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(), \n",
        "                metrics=['accuracy'],\n",
        "                steps_per_execution = 100)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "feMor9xvPq3L",
        "outputId": "766a1b66-68bb-4384-9436-cf5c2baffa88"
      },
      "source": [
        "\n",
        "# model.fit(x_train, y_train, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-43380bce21d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVyUWbYWgXfW"
      },
      "source": [
        "# predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STa0baZSjtpZ"
      },
      "source": [
        "# print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g1VlM8xkeZX",
        "outputId": "6a75015f-d046-4137-bb50-e437cc4cafec"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "scores, histories = list(), list()\n",
        "for itrain, ival in kfold.split(x_train):\n",
        "\n",
        "  model = model2()\n",
        "  trainx = x_train[itrain]\n",
        "  trainy = y_train[itrain]\n",
        "  valx = x_train[ival]\n",
        "  valy = y_train[ival]\n",
        "\n",
        "  # trainx = np.repeat(trainx, 2, axis=0)\n",
        "  # trainy = np.repeat(trainy, 2, axis=0)\n",
        "\n",
        "  \n",
        "  # for i in range(len(trainx)):\n",
        "  #   trainx[i] = tf.image.random_flip_left_right(trainx[i])\n",
        "  # import skimage\n",
        "  # for i in range(len(trainx)):\n",
        "  #   trainx[i] = layers.Lambda(lambda image: resize_images(x=trainx[i], height_factor=2, width_factor=2, data_format='channels_last'))\n",
        "\n",
        "  history = model.fit(trainx, trainy, batch_size=64, epochs=40, validation_freq=5, validation_data=(valx,valy))\n",
        "\n",
        "  loss, acc = model.evaluate(valx, valy, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "  scores.append(acc)\n",
        "  histories.append(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_114 (Dense)           (None, 28, 28, 256)       512       \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 28, 28, 256)       65792     \n",
            "                                                                 \n",
            " conv2d_142 (Conv2D)         (None, 28, 28, 32)        73760     \n",
            "                                                                 \n",
            " batch_normalization_168 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_143 (Conv2D)         (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_169 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_174 (Dropout)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_144 (Conv2D)         (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_59 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_175 (Dropout)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_170 (Ba  (None, 14, 14, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_176 (Dropout)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_37 (Flatten)        (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_171 (Ba  (None, 512)              2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_177 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_172 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_178 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,224,970\n",
            "Trainable params: 13,223,050\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 1.5462 - accuracy: 0.5245\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 1.0660 - accuracy: 0.6614\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.9555 - accuracy: 0.6922\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.8739 - accuracy: 0.7152\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8135 - accuracy: 0.7309 - val_loss: 0.4824 - val_accuracy: 0.8216\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7654 - accuracy: 0.7418\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7322 - accuracy: 0.7535\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7000 - accuracy: 0.7639\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6698 - accuracy: 0.7724\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6441 - accuracy: 0.7784 - val_loss: 0.4357 - val_accuracy: 0.8361\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6296 - accuracy: 0.7846\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6123 - accuracy: 0.7914\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5831 - accuracy: 0.7971\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.8017\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5553 - accuracy: 0.8065 - val_loss: 0.3741 - val_accuracy: 0.8611\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5349 - accuracy: 0.8129\n",
            "Epoch 17/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5267 - accuracy: 0.8147\n",
            "Epoch 18/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5095 - accuracy: 0.8214\n",
            "Epoch 19/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5090 - accuracy: 0.8230\n",
            "Epoch 20/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4983 - accuracy: 0.8262 - val_loss: 0.3397 - val_accuracy: 0.8726\n",
            "Epoch 21/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4752 - accuracy: 0.8314\n",
            "Epoch 22/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4677 - accuracy: 0.8350\n",
            "Epoch 23/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4560 - accuracy: 0.8399\n",
            "Epoch 24/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4517 - accuracy: 0.8407\n",
            "Epoch 25/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4434 - accuracy: 0.8437 - val_loss: 0.3687 - val_accuracy: 0.8623\n",
            "Epoch 26/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4336 - accuracy: 0.8453\n",
            "Epoch 27/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4226 - accuracy: 0.8508\n",
            "Epoch 28/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4170 - accuracy: 0.8532\n",
            "Epoch 29/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4095 - accuracy: 0.8548\n",
            "Epoch 30/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4085 - accuracy: 0.8548 - val_loss: 0.3054 - val_accuracy: 0.8881\n",
            "Epoch 31/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4006 - accuracy: 0.8575\n",
            "Epoch 32/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3858 - accuracy: 0.8613\n",
            "Epoch 33/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3924 - accuracy: 0.8609\n",
            "Epoch 34/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3833 - accuracy: 0.8627\n",
            "Epoch 35/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3703 - accuracy: 0.8686 - val_loss: 0.3157 - val_accuracy: 0.8850\n",
            "Epoch 36/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3752 - accuracy: 0.8674\n",
            "Epoch 37/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3684 - accuracy: 0.8696\n",
            "Epoch 38/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3602 - accuracy: 0.8712\n",
            "Epoch 39/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3569 - accuracy: 0.8727\n",
            "Epoch 40/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3486 - accuracy: 0.8753 - val_loss: 0.2928 - val_accuracy: 0.8943\n",
            "> 89.430\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_119 (Dense)           (None, 28, 28, 256)       512       \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 28, 28, 256)       65792     \n",
            "                                                                 \n",
            " conv2d_146 (Conv2D)         (None, 28, 28, 32)        73760     \n",
            "                                                                 \n",
            " batch_normalization_173 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_174 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_179 (Dropout)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_148 (Conv2D)         (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_60 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_180 (Dropout)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_149 (Conv2D)         (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_175 (Ba  (None, 14, 14, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_181 (Dropout)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_38 (Flatten)        (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_176 (Ba  (None, 512)              2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_182 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_177 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_183 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,224,970\n",
            "Trainable params: 13,223,050\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.5955 - accuracy: 0.5187\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 1.0981 - accuracy: 0.6547\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.9804 - accuracy: 0.6866\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.8895 - accuracy: 0.7092\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8354 - accuracy: 0.7230 - val_loss: 0.4762 - val_accuracy: 0.8267\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7849 - accuracy: 0.7370\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7447 - accuracy: 0.7519\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7138 - accuracy: 0.7599\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6817 - accuracy: 0.7659\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6626 - accuracy: 0.7748 - val_loss: 0.4351 - val_accuracy: 0.8436\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6414 - accuracy: 0.7782\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6136 - accuracy: 0.7864\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5977 - accuracy: 0.7932\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5779 - accuracy: 0.8005\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5584 - accuracy: 0.8060 - val_loss: 0.3932 - val_accuracy: 0.8556\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5479 - accuracy: 0.8106\n",
            "Epoch 17/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5350 - accuracy: 0.8143\n",
            "Epoch 18/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5177 - accuracy: 0.8187\n",
            "Epoch 19/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5036 - accuracy: 0.8237\n",
            "Epoch 20/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4927 - accuracy: 0.8251 - val_loss: 0.3507 - val_accuracy: 0.8711\n",
            "Epoch 21/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4850 - accuracy: 0.8288\n",
            "Epoch 22/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4690 - accuracy: 0.8336\n",
            "Epoch 23/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4630 - accuracy: 0.8364\n",
            "Epoch 24/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4611 - accuracy: 0.8383\n",
            "Epoch 25/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4503 - accuracy: 0.8402 - val_loss: 0.3302 - val_accuracy: 0.8794\n",
            "Epoch 26/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4395 - accuracy: 0.8450\n",
            "Epoch 27/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4330 - accuracy: 0.8478\n",
            "Epoch 28/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4295 - accuracy: 0.8493\n",
            "Epoch 29/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4186 - accuracy: 0.8514\n",
            "Epoch 30/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4126 - accuracy: 0.8532 - val_loss: 0.3140 - val_accuracy: 0.8824\n",
            "Epoch 31/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3994 - accuracy: 0.8594\n",
            "Epoch 32/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3994 - accuracy: 0.8584\n",
            "Epoch 33/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3868 - accuracy: 0.8621\n",
            "Epoch 34/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3870 - accuracy: 0.8642\n",
            "Epoch 35/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3844 - accuracy: 0.8641 - val_loss: 0.3398 - val_accuracy: 0.8746\n",
            "Epoch 36/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3743 - accuracy: 0.8665\n",
            "Epoch 37/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3708 - accuracy: 0.8681\n",
            "Epoch 38/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3671 - accuracy: 0.8690\n",
            "Epoch 39/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3610 - accuracy: 0.8726\n",
            "Epoch 40/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3543 - accuracy: 0.8743 - val_loss: 0.3067 - val_accuracy: 0.8880\n",
            "> 88.810\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_124 (Dense)           (None, 28, 28, 256)       512       \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 28, 28, 256)       65792     \n",
            "                                                                 \n",
            " conv2d_150 (Conv2D)         (None, 28, 28, 32)        73760     \n",
            "                                                                 \n",
            " batch_normalization_178 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_151 (Conv2D)         (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_179 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_184 (Dropout)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_152 (Conv2D)         (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_61 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_185 (Dropout)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_153 (Conv2D)         (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_180 (Ba  (None, 14, 14, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_186 (Dropout)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_39 (Flatten)        (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_181 (Ba  (None, 512)              2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_187 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_182 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_188 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,224,970\n",
            "Trainable params: 13,223,050\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 1.5759 - accuracy: 0.5208\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 1.0720 - accuracy: 0.6570\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.9565 - accuracy: 0.6911\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.8743 - accuracy: 0.7140\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.8081 - accuracy: 0.7285 - val_loss: 0.5077 - val_accuracy: 0.8163\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7749 - accuracy: 0.7403\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7370 - accuracy: 0.7482\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7080 - accuracy: 0.7602\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6786 - accuracy: 0.7658\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6587 - accuracy: 0.7718 - val_loss: 0.4467 - val_accuracy: 0.8330\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6277 - accuracy: 0.7821\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6077 - accuracy: 0.7910\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5829 - accuracy: 0.7950\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5733 - accuracy: 0.8001\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5560 - accuracy: 0.8048 - val_loss: 0.3941 - val_accuracy: 0.8579\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.8104\n",
            "Epoch 17/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5302 - accuracy: 0.8136\n",
            "Epoch 18/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5171 - accuracy: 0.8185\n",
            "Epoch 19/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5055 - accuracy: 0.8216\n",
            "Epoch 20/40\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.4902 - accuracy: 0.8242 - val_loss: 0.3545 - val_accuracy: 0.8728\n",
            "Epoch 21/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4793 - accuracy: 0.8323\n",
            "Epoch 22/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4700 - accuracy: 0.8329\n",
            "Epoch 23/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4624 - accuracy: 0.8369\n",
            "Epoch 24/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4558 - accuracy: 0.8398\n",
            "Epoch 25/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4509 - accuracy: 0.8393 - val_loss: 0.3490 - val_accuracy: 0.8728\n",
            "Epoch 26/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4356 - accuracy: 0.8460\n",
            "Epoch 27/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4315 - accuracy: 0.8454\n",
            "Epoch 28/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4233 - accuracy: 0.8489\n",
            "Epoch 29/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4174 - accuracy: 0.8533\n",
            "Epoch 30/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4165 - accuracy: 0.8541 - val_loss: 0.3300 - val_accuracy: 0.8813\n",
            "Epoch 31/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4046 - accuracy: 0.8565\n",
            "Epoch 32/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3987 - accuracy: 0.8564\n",
            "Epoch 33/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3955 - accuracy: 0.8591\n",
            "Epoch 34/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3880 - accuracy: 0.8618\n",
            "Epoch 35/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3788 - accuracy: 0.8636 - val_loss: 0.3115 - val_accuracy: 0.8887\n",
            "Epoch 36/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3752 - accuracy: 0.8666\n",
            "Epoch 37/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3720 - accuracy: 0.8676\n",
            "Epoch 38/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3618 - accuracy: 0.8712\n",
            "Epoch 39/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3591 - accuracy: 0.8729\n",
            "Epoch 40/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3509 - accuracy: 0.8733 - val_loss: 0.3086 - val_accuracy: 0.8891\n",
            "> 88.830\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_129 (Dense)           (None, 28, 28, 256)       512       \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 28, 28, 256)       65792     \n",
            "                                                                 \n",
            " conv2d_154 (Conv2D)         (None, 28, 28, 32)        73760     \n",
            "                                                                 \n",
            " batch_normalization_183 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_155 (Conv2D)         (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_184 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_189 (Dropout)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_156 (Conv2D)         (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_62 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_190 (Dropout)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_157 (Conv2D)         (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_185 (Ba  (None, 14, 14, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_191 (Dropout)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_40 (Flatten)        (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_186 (Ba  (None, 512)              2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_192 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_187 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_193 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,224,970\n",
            "Trainable params: 13,223,050\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 1.5501 - accuracy: 0.5276\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 1.0673 - accuracy: 0.6634\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.9402 - accuracy: 0.6945\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.8690 - accuracy: 0.7170\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.8056 - accuracy: 0.7351 - val_loss: 0.5042 - val_accuracy: 0.8166\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7673 - accuracy: 0.7419\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7202 - accuracy: 0.7575\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6921 - accuracy: 0.7660\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6671 - accuracy: 0.7719\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6421 - accuracy: 0.7794 - val_loss: 0.4159 - val_accuracy: 0.8487\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6176 - accuracy: 0.7861\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5962 - accuracy: 0.7914\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5761 - accuracy: 0.8008\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.8033\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5544 - accuracy: 0.8071 - val_loss: 0.3964 - val_accuracy: 0.8525\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5292 - accuracy: 0.8147\n",
            "Epoch 17/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5194 - accuracy: 0.8170\n",
            "Epoch 18/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5097 - accuracy: 0.8233\n",
            "Epoch 19/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4945 - accuracy: 0.8250\n",
            "Epoch 20/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4878 - accuracy: 0.8280 - val_loss: 0.3509 - val_accuracy: 0.8733\n",
            "Epoch 21/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4740 - accuracy: 0.8325\n",
            "Epoch 22/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4668 - accuracy: 0.8355\n",
            "Epoch 23/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4619 - accuracy: 0.8383\n",
            "Epoch 24/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4503 - accuracy: 0.8390\n",
            "Epoch 25/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4453 - accuracy: 0.8451 - val_loss: 0.3354 - val_accuracy: 0.8781\n",
            "Epoch 26/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4346 - accuracy: 0.8477\n",
            "Epoch 27/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4251 - accuracy: 0.8502\n",
            "Epoch 28/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4243 - accuracy: 0.8491\n",
            "Epoch 29/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4192 - accuracy: 0.8503\n",
            "Epoch 30/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4118 - accuracy: 0.8546 - val_loss: 0.3502 - val_accuracy: 0.8719\n",
            "Epoch 31/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4070 - accuracy: 0.8567\n",
            "Epoch 32/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3975 - accuracy: 0.8585\n",
            "Epoch 33/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3995 - accuracy: 0.8583\n",
            "Epoch 34/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3838 - accuracy: 0.8644\n",
            "Epoch 35/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3818 - accuracy: 0.8626 - val_loss: 0.3159 - val_accuracy: 0.8854\n",
            "Epoch 36/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3771 - accuracy: 0.8657\n",
            "Epoch 37/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3629 - accuracy: 0.8709\n",
            "Epoch 38/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3641 - accuracy: 0.8705\n",
            "Epoch 39/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3558 - accuracy: 0.8733\n",
            "Epoch 40/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3499 - accuracy: 0.8746 - val_loss: 0.3195 - val_accuracy: 0.8840\n",
            "> 88.350\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_134 (Dense)           (None, 28, 28, 256)       512       \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 28, 28, 256)       65792     \n",
            "                                                                 \n",
            " conv2d_158 (Conv2D)         (None, 28, 28, 32)        73760     \n",
            "                                                                 \n",
            " batch_normalization_188 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_159 (Conv2D)         (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_189 (Ba  (None, 28, 28, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_194 (Dropout)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_160 (Conv2D)         (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_63 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_195 (Dropout)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_161 (Conv2D)         (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_190 (Ba  (None, 14, 14, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_196 (Dropout)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_41 (Flatten)        (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_191 (Ba  (None, 512)              2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_197 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_192 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_198 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,224,970\n",
            "Trainable params: 13,223,050\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 1.5245 - accuracy: 0.5343\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 1.0665 - accuracy: 0.6628\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.9480 - accuracy: 0.6935\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.8709 - accuracy: 0.7150\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.8089 - accuracy: 0.7307 - val_loss: 0.4950 - val_accuracy: 0.8165\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7652 - accuracy: 0.7465\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7322 - accuracy: 0.7528\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7056 - accuracy: 0.7618\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6818 - accuracy: 0.7684\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6577 - accuracy: 0.7715 - val_loss: 0.4841 - val_accuracy: 0.8227\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6278 - accuracy: 0.7836\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6100 - accuracy: 0.7902\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5942 - accuracy: 0.7943\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5740 - accuracy: 0.8016\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5627 - accuracy: 0.8054 - val_loss: 0.4006 - val_accuracy: 0.8547\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.8097\n",
            "Epoch 17/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.8156\n",
            "Epoch 18/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5139 - accuracy: 0.8205\n",
            "Epoch 19/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5079 - accuracy: 0.8208\n",
            "Epoch 20/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4947 - accuracy: 0.8262 - val_loss: 0.3514 - val_accuracy: 0.8725\n",
            "Epoch 21/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4840 - accuracy: 0.8312\n",
            "Epoch 22/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4743 - accuracy: 0.8322\n",
            "Epoch 23/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4610 - accuracy: 0.8368\n",
            "Epoch 24/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4514 - accuracy: 0.8419\n",
            "Epoch 25/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4480 - accuracy: 0.8419 - val_loss: 0.3411 - val_accuracy: 0.8729\n",
            "Epoch 26/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4380 - accuracy: 0.8457\n",
            "Epoch 27/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4310 - accuracy: 0.8482\n",
            "Epoch 28/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4231 - accuracy: 0.8510\n",
            "Epoch 29/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4153 - accuracy: 0.8539\n",
            "Epoch 30/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4072 - accuracy: 0.8572 - val_loss: 0.3200 - val_accuracy: 0.8828\n",
            "Epoch 31/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4057 - accuracy: 0.8553\n",
            "Epoch 32/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3975 - accuracy: 0.8597\n",
            "Epoch 33/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3883 - accuracy: 0.8614\n",
            "Epoch 34/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3833 - accuracy: 0.8636\n",
            "Epoch 35/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3827 - accuracy: 0.8658 - val_loss: 0.3129 - val_accuracy: 0.8839\n",
            "Epoch 36/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3762 - accuracy: 0.8657\n",
            "Epoch 37/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3731 - accuracy: 0.8680\n",
            "Epoch 38/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3660 - accuracy: 0.8694\n",
            "Epoch 39/40\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3656 - accuracy: 0.8714\n",
            "Epoch 40/40\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3554 - accuracy: 0.8720 - val_loss: 0.3010 - val_accuracy: 0.8890\n",
            "> 88.990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "azp0pRjm-kDj",
        "outputId": "1c74b7a2-3657-4aab-852b-6e75f1cfcd49"
      },
      "source": [
        "model = model3()\n",
        "\n",
        "x_train = np.repeat(x_train, 4, axis=0)\n",
        "y_train = np.repeat(y_train, 4, axis=0)\n",
        "\n",
        "\n",
        "import skimage\n",
        "for i in range(len(x_train)):\n",
        "  x_train[i] = skimage.util.random_noise(x_train[i], mode='gaussian')\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=64)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_362 (Conv2D)         (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_329 (Ba  (None, 28, 28, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_363 (Conv2D)         (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_330 (Ba  (None, 28, 28, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_427 (Dropout)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_364 (Conv2D)         (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_195 (MaxPooli  (None, 14, 14, 128)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_428 (Dropout)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_365 (Conv2D)         (None, 14, 14, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_331 (Ba  (None, 14, 14, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_429 (Dropout)       (None, 14, 14, 256)       0         \n",
            "                                                                 \n",
            " flatten_88 (Flatten)        (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 256)               12845312  \n",
            "                                                                 \n",
            " batch_normalization_332 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_430 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_333 (Ba  (None, 512)              2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_431 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_204 (Dense)           (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,393,226\n",
            "Trainable params: 13,390,922\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3125/3125 [==============================] - 21s 7ms/step - loss: 0.9853 - accuracy: 0.6811\n",
            "Epoch 2/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.6711 - accuracy: 0.7668\n",
            "Epoch 3/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.5579 - accuracy: 0.8035\n",
            "Epoch 4/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.4925 - accuracy: 0.8260\n",
            "Epoch 5/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.4498 - accuracy: 0.8397\n",
            "Epoch 6/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.4167 - accuracy: 0.8504\n",
            "Epoch 7/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3889 - accuracy: 0.8593\n",
            "Epoch 8/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3686 - accuracy: 0.8657\n",
            "Epoch 9/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3510 - accuracy: 0.8728\n",
            "Epoch 10/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3296 - accuracy: 0.8807\n",
            "Epoch 11/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3163 - accuracy: 0.8843\n",
            "Epoch 12/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3032 - accuracy: 0.8892\n",
            "Epoch 13/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2895 - accuracy: 0.8938\n",
            "Epoch 14/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2761 - accuracy: 0.8994\n",
            "Epoch 15/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2717 - accuracy: 0.9007\n",
            "Epoch 16/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2573 - accuracy: 0.9058\n",
            "Epoch 17/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2491 - accuracy: 0.9090\n",
            "Epoch 18/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2397 - accuracy: 0.9118\n",
            "Epoch 19/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2319 - accuracy: 0.9155\n",
            "Epoch 20/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2263 - accuracy: 0.9170\n",
            "Epoch 21/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2174 - accuracy: 0.9211\n",
            "Epoch 22/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2110 - accuracy: 0.9226\n",
            "Epoch 23/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2063 - accuracy: 0.9243\n",
            "Epoch 24/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1987 - accuracy: 0.9274\n",
            "Epoch 25/50\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1950 - accuracy: 0.9285\n",
            "Epoch 26/50\n",
            "1200/3125 [==========>...................] - ETA: 5s - loss: 0.1887 - accuracy: 0.9315"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-181-dd5b1267fa4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmsEvTu2MKf9"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNJntYNfNQVo",
        "outputId": "e8608f9f-4588-441a-8bb1-79882385c190"
      },
      "source": [
        "print(predictions)\n",
        "plain_pred = list()\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "  plain_pred.append(list(predictions[i]).index(max(predictions[i])))\n",
        "\n",
        "print(plain_pred)\n",
        "new_array = pd.DataFrame(plain_pred)\n",
        "print(new_array)\n",
        "new_array.to_csv('/content/new.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6.12151837e-07 6.75842386e-07 4.88067381e-05 ... 1.04973522e-04\n",
            "  7.40358175e-09 9.99709785e-01]\n",
            " [5.98723884e-04 5.64171598e-10 1.20521108e-07 ... 1.28108195e-05\n",
            "  1.76101900e-09 5.98126266e-04]\n",
            " [2.71697936e-05 2.28754871e-07 9.99161482e-01 ... 8.01147256e-12\n",
            "  3.85954131e-08 4.19011596e-11]\n",
            " ...\n",
            " [7.31359178e-04 4.77487883e-05 4.50430103e-02 ... 9.28685722e-07\n",
            "  5.81001700e-07 4.62648222e-06]\n",
            " [8.84202450e-07 4.36346792e-10 5.24360394e-06 ... 1.95419947e-08\n",
            "  9.99863982e-01 2.57219790e-06]\n",
            " [1.91141226e-06 4.77119544e-09 2.39996923e-04 ... 6.33695709e-06\n",
            "  6.03017085e-08 1.08126005e-05]]\n",
            "[9, 5, 2, 1, 8, 3, 8, 9, 9, 9, 3, 8, 3, 1, 5, 1, 3, 5, 7, 2, 1, 8, 7, 6, 3, 8, 9, 0, 5, 9, 7, 0, 8, 0, 7, 5, 7, 2, 1, 7, 5, 1, 0, 6, 1, 0, 0, 6, 1, 4, 8, 4, 4, 9, 4, 0, 8, 8, 1, 6, 5, 5, 2, 1, 7, 2, 2, 6, 4, 4, 6, 6, 5, 5, 5, 6, 9, 7, 0, 2, 2, 8, 0, 9, 3, 7, 9, 6, 3, 9, 6, 1, 1, 4, 7, 4, 2, 2, 3, 2, 1, 5, 7, 9, 4, 5, 9, 9, 8, 8, 4, 2, 6, 5, 5, 6, 2, 7, 1, 4, 2, 9, 3, 7, 2, 0, 8, 4, 8, 7, 9, 6, 4, 4, 8, 1, 4, 7, 4, 8, 2, 0, 3, 9, 0, 4, 5, 2, 6, 8, 2, 7, 4, 0, 5, 9, 2, 0, 9, 4, 3, 1, 4, 6, 0, 3, 8, 6, 2, 5, 2, 6, 2, 4, 5, 2, 6, 3, 3, 4, 0, 9, 9, 8, 0, 0, 8, 0, 5, 6, 2, 1, 4, 1, 1, 7, 3, 3, 5, 7, 2, 2, 8, 7, 7, 4, 8, 9, 8, 2, 0, 6, 9, 5, 7, 2, 1, 0, 2, 2, 1, 3, 5, 7, 2, 5, 0, 3, 3, 0, 7, 9, 1, 1, 8, 0, 2, 1, 7, 1, 3, 3, 9, 7, 5, 2, 1, 8, 7, 8, 4, 8, 2, 0, 5, 0, 1, 0, 3, 4, 7, 6, 4, 3, 9, 2, 8, 7, 5, 6, 2, 2, 2, 5, 2, 0, 2, 9, 5, 2, 1, 1, 1, 5, 2, 2, 8, 8, 7, 8, 8, 7, 0, 7, 1, 0, 7, 0, 3, 9, 4, 0, 9, 6, 4, 2, 2, 3, 0, 1, 2, 6, 0, 8, 0, 8, 1, 6, 3, 8, 7, 9, 4, 0, 9, 6, 8, 3, 8, 1, 1, 8, 4, 2, 9, 8, 5, 2, 8, 4, 5, 0, 2, 8, 8, 6, 5, 0, 3, 2, 7, 6, 2, 9, 9, 3, 7, 8, 8, 6, 7, 1, 4, 5, 4, 0, 2, 7, 4, 1, 4, 1, 8, 8, 3, 3, 8, 6, 4, 0, 2, 2, 5, 3, 1, 9, 7, 8, 8, 7, 3, 9, 6, 5, 4, 2, 6, 7, 6, 3, 4, 7, 6, 5, 6, 9, 9, 7, 6, 7, 0, 4, 9, 6, 9, 9, 9, 1, 5, 5, 2, 0, 6, 6, 6, 0, 0, 6, 8, 7, 5, 8, 2, 4, 0, 6, 8, 6, 5, 7, 3, 7, 8, 3, 8, 5, 5, 1, 2, 1, 2, 9, 7, 1, 4, 5, 8, 4, 0, 4, 3, 3, 6, 5, 0, 4, 5, 9, 3, 0, 5, 8, 9, 0, 0, 6, 6, 0, 4, 9, 1, 7, 8, 1, 5, 8, 4, 1, 8, 4, 4, 9, 2, 2, 7, 7, 4, 6, 7, 4, 6, 5, 0, 6, 6, 4, 3, 1, 9, 0, 5, 0, 7, 0, 7, 4, 6, 5, 7, 8, 7, 1, 2, 9, 1, 3, 0, 0, 6, 6, 8, 1, 0, 4, 9, 6, 8, 7, 3, 7, 4, 7, 1, 1, 3, 2, 4, 4, 7, 1, 1, 4, 7, 5, 7, 6, 8, 5, 7, 3, 8, 4, 8, 8, 7, 7, 5, 2, 0, 3, 1, 5, 6, 2, 9, 7, 1, 3, 2, 6, 0, 7, 9, 7, 8, 5, 7, 2, 3, 8, 9, 0, 7, 0, 3, 5, 9, 9, 5, 4, 7, 9, 3, 4, 5, 9, 0, 4, 8, 1, 4, 4, 5, 5, 5, 8, 8, 4, 9, 0, 7, 1, 0, 8, 2, 5, 2, 9, 7, 7, 1, 4, 2, 0, 2, 5, 0, 0, 5, 1, 8, 4, 8, 3, 6, 3, 4, 9, 1, 1, 4, 1, 7, 8, 8, 5, 5, 4, 4, 9, 1, 1, 2, 8, 2, 8, 2, 8, 3, 2, 6, 5, 9, 0, 8, 2, 5, 6, 4, 5, 7, 0, 3, 4, 8, 2, 7, 6, 6, 6, 4, 4, 0, 0, 1, 8, 6, 5, 3, 7, 6, 7, 0, 0, 2, 5, 8, 7, 9, 1, 9, 6, 7, 4, 2, 7, 7, 9, 5, 7, 2, 7, 5, 0, 3, 6, 2, 1, 4, 5, 0, 9, 9, 3, 0, 3, 7, 3, 2, 3, 4, 1, 7, 9, 1, 0, 5, 8, 2, 9, 0, 8, 9, 4, 0, 7, 6, 5, 8, 9, 3, 6, 9, 0, 7, 6, 1, 5, 3, 8, 5, 0, 5, 8, 9, 8, 8, 3, 5, 4, 1, 1, 6, 7, 3, 2, 5, 9, 7, 6, 4, 4, 7, 6, 9, 5, 6, 3, 5, 4, 7, 5, 0, 0, 8, 4, 4, 9, 4, 9, 7, 5, 1, 1, 1, 4, 5, 1, 7, 8, 0, 0, 7, 1, 0, 5, 7, 0, 7, 7, 4, 7, 8, 6, 7, 7, 5, 2, 2, 8, 2, 4, 4, 1, 1, 7, 8, 4, 0, 4, 9, 0, 4, 1, 2, 9, 8, 8, 3, 3, 1, 2, 6, 8, 0, 7, 8, 2, 9, 5, 9, 6, 5, 9, 9, 5, 9, 8, 2, 0, 9, 3, 3, 0, 2, 1, 0, 2, 5, 3, 6, 3, 0, 5, 0, 8, 9, 1, 4, 1, 2, 5, 5, 8, 2, 0, 1, 1, 9, 8, 5, 2, 9, 4, 5, 5, 2, 0, 8, 1, 4, 5, 1, 9, 5, 5, 9, 4, 2, 4, 7, 0, 5, 3, 8, 1, 8, 5, 9, 9, 8, 1, 1, 6, 2, 1, 9, 4, 3, 7, 3, 4, 7, 6, 1, 2, 0, 4, 6, 0, 9, 1, 2, 0, 2, 6, 7, 4, 3, 3, 8, 4, 2, 8, 0, 7, 2, 5, 3, 5, 1, 1, 0, 9, 9, 1, 1, 0, 6, 7, 4, 7, 8, 7, 4, 0, 2, 9, 4, 1, 8, 1, 8, 5, 4, 7, 7, 9, 2, 0, 2, 2, 7, 4, 7, 7, 3, 8, 0, 0, 1, 4, 7, 8, 1, 6, 2, 8, 7, 9, 5, 9, 4, 3, 9, 2, 8, 4, 1, 4, 6, 3, 2, 0, 7, 1, 6, 8, 3, 0, 5, 1, 6, 9, 9, 8, 2, 8, 8, 0, 5, 3, 9, 8, 7, 4, 2, 8, 1, 5, 3, 6, 0, 4, 2, 6, 1, 9, 8, 0, 5, 6, 1, 2, 1, 7, 3, 6, 1, 9, 7, 3, 7, 2, 4, 0, 0, 5, 3, 1, 4, 2, 5, 3, 5, 4, 4, 4, 8, 7, 2, 6, 7, 9, 6, 3, 5, 7, 1, 3, 2, 9, 1, 0, 1, 5, 5, 9, 4, 5, 0, 3, 2, 6, 6, 9, 3, 9, 4, 1, 2, 6, 2, 5, 3, 2, 9, 2, 3, 2, 5, 6, 7, 9, 2, 6, 3, 3, 4, 9, 8, 7, 8, 4, 2, 2, 6, 4, 3, 1, 4, 0, 0, 1, 3, 0, 8, 2, 9, 0, 8, 2, 1, 2, 1, 3, 2, 5, 9, 7, 9, 6, 0, 0, 6, 3, 3, 6, 1, 6, 2, 8, 7, 1, 9, 4, 0, 7, 1, 8, 9, 8, 2, 4, 7, 6, 4, 6, 5, 5, 7, 0, 9, 8, 9, 7, 0, 7, 1, 0, 2, 7, 1, 5, 6, 5, 2, 1, 3, 2, 9, 6, 9, 9, 2, 6, 6, 8, 8, 8, 1, 5, 4, 7, 0, 2, 6, 0, 5, 5, 6, 8, 4, 3, 5, 7, 5, 6, 1, 8, 7, 4, 5, 0, 0, 9, 3, 7, 0, 5, 4, 3, 9, 8, 0, 1, 4, 1, 5, 5, 1, 5, 3, 0, 7, 2, 1, 0, 7, 8, 0, 5, 0, 2, 7, 8, 7, 1, 6, 2, 9, 5, 8, 3, 5, 9, 6, 0, 6, 8, 6, 5, 7, 5, 6, 4, 8, 0, 1, 0, 5, 7, 5, 6, 1, 6, 4, 5, 7, 3, 2, 5, 9, 8, 0, 2, 2, 8, 6, 4, 5, 1, 0, 7, 7, 2, 9, 1, 5, 5, 3, 3, 4, 3, 1, 4, 8, 4, 9, 5, 8, 5, 0, 3, 0, 8, 6, 0, 7, 3, 7, 8, 9, 1, 5, 2, 9, 0, 2, 6, 7, 9, 2, 0, 3, 8, 5, 5, 4, 8, 8, 5, 8, 3, 1, 8, 5, 5, 4, 6, 5, 1, 7, 8, 2, 9, 5, 4, 2, 8, 7, 4, 2, 7, 1, 4, 9, 8, 0, 5, 4, 3, 2, 8, 2, 2, 3, 0, 2, 1, 5, 2, 0, 1, 4, 2, 6, 6, 0, 3, 2, 1, 7, 5, 7, 9, 7, 2, 2, 2, 5, 5, 7, 6, 4, 4, 9, 2, 1, 2, 6, 4, 6, 8, 1, 8, 9, 1, 9, 2, 8, 0, 3, 3, 4, 7, 2, 1, 1, 2, 8, 9, 6, 8, 1, 7, 0, 7, 2, 8, 4, 9, 9, 8, 7, 0, 4, 2, 4, 6, 8, 4, 0, 2, 4, 2, 4, 5, 8, 5, 5, 5, 6, 1, 2, 0, 9, 0, 0, 8, 6, 6, 9, 5, 8, 4, 9, 6, 0, 3, 8, 9, 1, 4, 0, 1, 3, 3, 4, 7, 1, 4, 1, 8, 0, 6, 2, 8, 4, 4, 2, 0, 5, 5, 2, 7, 1, 0, 0, 6, 4, 1, 3, 0, 2, 6, 3, 8, 2, 1, 2, 2, 2, 5, 2, 0, 2, 6, 9, 8, 7, 7, 8, 3, 0, 6, 3, 3, 2, 7, 0, 9, 3, 9, 8, 1, 2, 8, 8, 8, 9, 3, 7, 9, 8, 0, 0, 9, 9, 3, 4, 1, 9, 2, 3, 7, 5, 2, 9, 6, 2, 2, 9, 7, 4, 5, 7, 3, 8, 8, 8, 8, 8, 6, 8, 4, 2, 5, 4, 8, 0, 2, 6, 2, 3, 9, 8, 1, 5, 1, 3, 4, 9, 3, 2, 5, 7, 6, 5, 7, 5, 2, 7, 0, 7, 2, 7, 1, 5, 9, 4, 1, 2, 8, 4, 2, 2, 3, 4, 0, 8, 2, 2, 8, 4, 9, 2, 4, 5, 0, 4, 0, 8, 1, 4, 3, 7, 5, 9, 2, 0, 7, 5, 0, 4, 2, 2, 4, 5, 5, 1, 5, 9, 6, 1, 6, 8, 3, 5, 5, 2, 7, 0, 3, 5, 4, 1, 1, 5, 9, 1, 7, 9, 4, 0, 3, 7, 3, 1, 9, 2, 4, 3, 2, 9, 3, 3, 0, 0, 6, 5, 7, 2, 4, 8, 3, 7, 8, 7, 1, 8, 7, 9, 3, 0, 8, 5, 1, 8, 8, 8, 6, 4, 2, 3, 6, 7, 3, 0, 8, 2, 5, 5, 6, 4, 7, 3, 4, 1, 9, 9, 3, 3, 4, 5, 0, 0, 9, 8, 9, 9, 2, 5, 4, 1, 1, 7, 2, 6, 1, 9, 5, 8, 0, 9, 3, 6, 2, 8, 1, 0, 9, 2, 0, 7, 1, 1, 9, 7, 9, 7, 5, 5, 1, 2, 1, 2, 0, 4, 3, 9, 5, 4, 9, 6, 1, 5, 8, 7, 8, 1, 0, 2, 2, 7, 7, 4, 0, 5, 7, 0, 2, 4, 8, 8, 4, 4, 3, 0, 0, 4, 1, 0, 8, 4, 1, 5, 1, 1, 1, 2, 8, 1, 0, 6, 9, 5, 7, 5, 4, 8, 2, 8, 3, 4, 6, 7, 5, 6, 8, 8, 5, 6, 5, 3, 1, 3, 9, 6, 5, 2, 8, 1, 2, 3, 8, 6, 7, 9, 2, 0, 8, 7, 0, 7, 0, 3, 3, 3, 7, 2, 9, 7, 8, 7, 6, 3, 3, 6, 0, 4, 4, 7, 6, 5, 6, 9, 0, 3, 6, 3, 9, 5, 4, 4, 0, 7, 6, 1, 1, 2, 9, 6, 8, 2, 5, 2, 0, 3, 2, 6, 3, 3, 2, 6, 0, 7, 2, 7, 9, 1, 0, 5, 7, 4, 3, 7, 9, 2, 2, 5, 0, 7, 1, 2, 4, 2, 1, 3, 7, 5, 4, 5, 8, 7, 8, 7, 8, 6, 4, 6, 4, 8, 1, 4, 8, 8, 9, 5, 0, 5, 9, 0, 2, 2, 4, 0, 8, 1, 5, 6, 9, 0, 9, 0, 8, 0, 7, 5, 4, 7, 9, 9, 4, 5, 4, 2, 0, 3, 9, 2, 8, 3, 8, 7, 8, 3, 8, 8, 1, 0, 8, 5, 1, 2, 7, 9, 1, 2, 3, 2, 8, 9, 1, 0, 4, 4, 9, 9, 9, 5, 3, 9, 5, 0, 1, 9, 2, 9, 8, 5, 6, 2, 8, 9, 3, 0, 8, 5, 8, 0, 0, 0, 7, 5, 1, 9, 9, 2, 9, 7, 5, 8, 3, 4, 4, 5, 4, 9, 0, 8, 0, 9, 7, 5, 7, 7, 2, 4, 8, 7, 4, 9, 2, 7, 5, 5, 9, 5, 1, 7, 7, 9, 7, 5, 7, 1, 8, 5, 3, 3, 7, 0, 8, 0, 7, 8, 1, 0, 7, 1, 3, 8, 0, 5, 4, 3, 6, 9, 4, 0, 2, 7, 0, 7, 4, 4, 5, 0, 0, 9, 5, 4, 9, 0, 0, 6, 4, 8, 3, 0, 3, 3, 9, 8, 0, 3, 9, 9, 3, 3, 1, 7, 2, 8, 9, 4, 0, 6, 1, 9, 1, 2, 7, 9, 0, 6, 0, 7, 0, 4, 4, 1, 2, 3, 1, 2, 1, 7, 1, 7, 3, 7, 8, 1, 9, 8, 7, 6, 0, 7, 4, 2, 2, 9, 6, 5, 7, 9, 4, 3, 3, 3, 1, 2, 7, 9, 5, 9, 7, 1, 0, 3, 2, 2, 9, 2, 5, 7, 5, 6, 5, 1, 1, 4, 1, 0, 5, 5, 8, 5, 1, 9, 1, 3, 6, 0, 5, 6, 9, 6, 3, 5, 5, 5, 9, 8, 3, 0, 2, 6, 4, 5, 2, 6, 4, 2, 4, 8, 2, 8, 0, 3, 3, 6, 5, 3, 1, 2, 0, 3, 0, 0, 4, 9, 9, 0, 9, 5, 1, 4, 0, 3, 5, 0, 5, 7, 2, 6, 8, 1, 3, 5, 9, 4, 4, 3, 3, 7, 9, 7, 2, 2, 2, 5, 0, 6, 6, 2, 7, 1, 0, 5, 8, 8, 1, 1, 0, 7, 0, 0, 2, 9, 3, 1, 0, 1, 1, 5, 4, 2, 5, 5, 0, 5, 0, 0, 6, 3, 1, 4, 2, 5, 9, 5, 0, 3, 3, 3, 1, 6, 2, 6, 0, 8, 2, 0, 3, 0, 0, 2, 5, 7, 5, 9, 7, 5, 3, 7, 0, 8, 6, 2, 1, 3, 0, 0, 4, 2, 9, 8, 6, 6, 9, 4, 4, 3, 1, 1, 0, 4, 3, 2, 3, 8, 6, 7, 6, 0, 8, 5, 0, 3, 8, 1, 1, 4, 7, 3, 4, 4, 1, 8, 8, 1, 1, 5, 4, 6, 5, 2, 0, 6, 3, 6, 9, 5, 4, 2, 9, 3, 3, 6, 2, 7, 0, 3, 4, 6, 6, 6, 1, 8, 9, 9, 2, 0, 2, 5, 9, 5, 1, 9, 9, 3, 3, 3, 6, 7, 1, 3, 4, 7, 4, 5, 2, 9, 9, 1, 8, 4, 9, 0, 1, 0, 7, 0, 8, 4, 8, 7, 5, 5, 7, 8, 5, 3, 1, 4, 0, 2, 1, 5, 1, 1, 2, 1, 2, 4, 7, 9, 2, 4, 1, 3, 6, 7, 4, 1, 8, 6, 9, 3, 4, 8, 2, 1, 5, 2, 2, 5, 4, 8, 7, 4, 3, 3, 2, 7, 8, 2, 7, 7, 0, 6, 4, 0, 0, 2, 1, 9, 8, 2, 7, 1, 0, 2, 1, 4, 0, 3, 7, 2, 1, 8, 1, 3, 5, 3, 8, 0, 2, 7, 4, 5, 2, 7, 8, 9, 0, 2, 4, 2, 2, 2, 3, 4, 4, 8, 8, 1, 5, 3, 5, 7, 6, 1, 5, 5, 6, 3, 3, 4, 5, 8, 8, 1, 0, 1, 8, 8, 5, 8, 7, 2, 6, 5, 7, 2, 9, 5, 4, 2, 2, 7, 0, 8, 4, 2, 2, 3, 0, 0, 8, 0, 5, 7, 7, 2, 6, 4, 3, 9, 0, 0, 3, 1, 5, 6, 3, 9, 6, 3, 4, 5, 4, 4, 8, 6, 2, 0, 7, 4, 0, 9, 0, 9, 7, 4, 3, 5, 7, 6, 0, 8, 1, 7, 7, 1, 5, 4, 1, 9, 4, 6, 6, 8, 1, 0, 7, 1, 4, 5, 9, 7, 2, 6, 1, 7, 2, 3, 7, 8, 5, 2, 1, 1, 4, 6, 6, 1, 6, 4, 8, 4, 2, 3, 6, 3, 2, 0, 0, 1, 6, 9, 4, 0, 4, 1, 1, 3, 1, 8, 4, 4, 6, 4, 7, 1, 5, 5, 4, 2, 6, 5, 4, 4, 8, 1, 7, 2, 8, 9, 2, 5, 3, 0, 2, 3, 0, 4, 5, 8, 5, 2, 5, 4, 7, 0, 4, 6, 1, 2, 9, 3, 7, 0, 1, 1, 6, 4, 1, 9, 7, 5, 8, 7, 7, 5, 1, 2, 4, 2, 2, 7, 6, 9, 8, 5, 1, 5, 2, 8, 1, 0, 8, 1, 3, 4, 9, 4, 5, 4, 3, 6, 7, 0, 3, 2, 1, 3, 7, 2, 8, 7, 2, 8, 6, 6, 1, 0, 0, 7, 3, 4, 6, 0, 6, 9, 4, 2, 3, 6, 4, 6, 9, 2, 5, 3, 6, 8, 8, 5, 7, 5, 9, 5, 0, 3, 1, 7, 6, 9, 2, 7, 9, 8, 9, 0, 1, 2, 7, 5, 4, 2, 8, 7, 9, 4, 2, 9, 9, 7, 6, 4, 4, 5, 0, 2, 2, 4, 6, 0, 4, 2, 4, 2, 3, 9, 7, 2, 1, 4, 5, 4, 7, 0, 8, 0, 7, 1, 2, 1, 4, 0, 8, 2, 7, 9, 3, 1, 9, 0, 6, 9, 1, 2, 3, 8, 1, 8, 2, 8, 8, 1, 6, 4, 7, 5, 1, 0, 3, 6, 3, 9, 4, 8, 7, 2, 8, 1, 7, 6, 9, 0, 1, 4, 3, 9, 7, 9, 6, 3, 3, 2, 7, 5, 0, 7, 8, 2, 2, 5, 6, 3, 7, 0, 1, 7, 2, 6, 1, 4, 2, 2, 7, 9, 4, 1, 9, 7, 2, 8, 1, 2, 9, 6, 0, 9, 7, 5, 0, 1, 7, 9, 1, 5, 2, 6, 7, 7, 9, 3, 7, 4, 6, 9, 2, 6, 4, 1, 5, 6, 7, 5, 1, 5, 2, 6, 2, 5, 1, 4, 9, 9, 3, 7, 4, 4, 6, 5, 0, 0, 8, 6, 7, 9, 9, 4, 4, 9, 6, 2, 8, 0, 9, 8, 2, 4, 9, 5, 3, 2, 6, 4, 0, 9, 3, 7, 7, 3, 4, 2, 1, 1, 7, 1, 7, 5, 5, 0, 8, 2, 1, 9, 3, 9, 7, 0, 5, 7, 0, 9, 3, 7, 0, 7, 7, 3, 9, 5, 3, 9, 0, 2, 8, 5, 8, 0, 7, 7, 8, 2, 0, 5, 1, 2, 8, 1, 0, 8, 7, 3, 7, 8, 6, 3, 5, 0, 2, 1, 6, 7, 8, 7, 0, 6, 2, 2, 1, 7, 0, 2, 0, 4, 6, 7, 8, 8, 3, 8, 5, 8, 8, 8, 6, 7, 4, 6, 0, 0, 6, 1, 7, 2, 7, 3, 3, 5, 3, 0, 2, 4, 3, 7, 2, 5, 2, 5, 8, 7, 9, 7, 6, 1, 7, 4, 5, 4, 5, 5, 7, 3, 7, 1, 9, 1, 1, 0, 2, 6, 7, 4, 0, 2, 8, 6, 4, 3, 9, 1, 2, 8, 6, 6, 7, 2, 7, 5, 8, 1, 9, 6, 9, 9, 8, 2, 6, 2, 0, 6, 6, 4, 4, 2, 9, 0, 4, 0, 8, 1, 6, 4, 3, 7, 4, 4, 4, 6, 4, 5, 1, 9, 3, 0, 1, 9, 4, 8, 3, 4, 5, 9, 1, 9, 7, 5, 1, 1, 1, 1, 7, 2, 8, 8, 4, 5, 1, 9, 0, 6, 1, 2, 8, 8, 2, 0, 0, 3, 0, 4, 2, 9, 2, 0, 5, 2, 1, 6, 2, 4, 1, 7, 1, 0, 5, 6, 5, 9, 0, 2, 0, 6, 1, 9, 1, 1, 2, 6, 6, 6, 8, 4, 5, 9, 3, 1, 6, 1, 9, 1, 3, 2, 7, 8, 8, 4, 7, 5, 0, 6, 4, 4, 9, 6, 3, 8, 2, 2, 5, 1, 6, 3, 7, 8, 4, 8, 5, 9, 5, 7, 4, 6, 8, 2, 1, 8, 9, 2, 7, 2, 7, 5, 1, 2, 2, 3, 5, 2, 1, 2, 5, 7, 8, 3, 6, 3, 2, 5, 2, 0, 1, 5, 8, 6, 4, 7, 7, 2, 4, 7, 8, 9, 1, 8, 2, 4, 3, 2, 6, 4, 0, 0, 3, 9, 1, 4, 4, 1, 4, 3, 4, 7, 6, 5, 7, 4, 2, 6, 7, 8, 0, 2, 3, 0, 7, 8, 5, 7, 0, 0, 2, 1, 2, 2, 5, 3, 3, 3, 0, 6, 0, 3, 8, 9, 8, 5, 8, 5, 6, 6, 7, 9, 4, 0, 0, 5, 5, 5, 5, 0, 5, 3, 8, 7, 8, 6, 5, 3, 8, 3, 3, 1, 8, 1, 5, 3, 2, 8, 1, 5, 1, 6, 1, 2, 8, 8, 9, 2, 0, 8, 9, 8, 6, 7, 8, 9, 9, 2, 3, 0, 2, 0, 4, 4, 7, 9, 1, 4, 6, 4, 6, 0, 1, 2, 7, 4, 8, 0, 1, 6, 4, 6, 5, 1, 0, 9, 1, 8, 2, 7, 8, 8, 7, 5, 2, 3, 4, 3, 2, 8, 3, 0, 7, 2, 1, 1, 2, 0, 1, 0, 7, 2, 9, 3, 5, 1, 9, 8, 3, 9, 1, 0, 4, 4, 7, 3, 7, 4, 0, 4, 6, 7, 8, 6, 0, 2, 8, 3, 7, 2, 5, 9, 6, 2, 9, 5, 0, 2, 9, 4, 7, 1, 1, 0, 4, 2, 0, 3, 0, 8, 3, 1, 9, 9, 0, 3, 4, 5, 3, 1, 7, 3, 8, 5, 2, 5, 9, 6, 0, 3, 8, 6, 9, 1, 9, 8, 9, 9, 0, 4, 4, 1, 8, 2, 4, 6, 8, 5, 5, 0, 2, 2, 4, 4, 8, 2, 6, 5, 2, 1, 0, 9, 0, 2, 8, 2, 4, 2, 9, 9, 3, 7, 5, 0, 8, 5, 1, 7, 0, 1, 0, 2, 8, 0, 8, 7, 8, 3, 2, 7, 9, 6, 9, 1, 2, 1, 4, 6, 2, 3, 0, 0, 2, 5, 7, 7, 9, 5, 7, 7, 0, 0, 4, 7, 4, 4, 8, 2, 7, 7, 8, 3, 8, 3, 0, 0, 0, 2, 0, 5, 8, 4, 7, 2, 9, 7, 5, 0, 6, 0, 9, 7, 9, 0, 8, 8, 0, 4, 0, 4, 0, 0, 4, 0, 2, 5, 0, 9, 0, 1, 9, 2, 4, 8, 3, 0, 7, 2, 0, 9, 9, 7, 6, 0, 0, 3, 5, 4, 0, 4, 7, 3, 9, 1, 0, 3, 4, 2, 9, 7, 3, 9, 2, 9, 9, 2, 8, 0, 6, 1, 6, 9, 0, 2, 2, 2, 4, 4, 4, 4, 8, 5, 4, 9, 1, 9, 9, 8, 4, 6, 3, 1, 9, 0, 3, 4, 3, 1, 2, 3, 0, 7, 0, 3, 0, 2, 2, 5, 9, 2, 6, 9, 1, 7, 6, 2, 2, 5, 6, 4, 5, 4, 2, 4, 6, 0, 6, 0, 3, 2, 5, 3, 4, 3, 5, 7, 2, 0, 1, 8, 2, 5, 1, 6, 6, 5, 9, 0, 2, 5, 8, 0, 5, 1, 8, 5, 7, 8, 0, 7, 7, 8, 7, 1, 7, 7, 3, 8, 5, 9, 6, 2, 7, 9, 1, 0, 5, 2, 0, 3, 3, 6, 7, 2, 6, 2, 4, 7, 3, 2, 8, 8, 7, 2, 4, 4, 3, 2, 0, 4, 7, 6, 9, 8, 0, 6, 3, 8, 9, 5, 4, 2, 3, 1, 0, 3, 9, 9, 0, 9, 4, 7, 1, 4, 2, 1, 6, 1, 7, 1, 2, 9, 6, 7, 1, 1, 7, 1, 9, 1, 7, 5, 0, 0, 1, 6, 2, 2, 4, 5, 7, 4, 1, 3, 9, 4, 4, 3, 7, 6, 2, 8, 8, 8, 9, 0, 0, 2, 8, 4, 8, 3, 0, 6, 4, 0, 4, 6, 0, 0, 0, 2, 8, 0, 8, 7, 1, 8, 9, 9, 9, 3, 4, 2, 6, 8, 8, 5, 5, 4, 2, 6, 0, 9, 9, 8, 0, 9, 0, 4, 7, 3, 3, 6, 4, 3, 0, 4, 8, 8, 5, 9, 8, 9, 5, 5, 1, 1, 6, 5, 6, 1, 0, 4, 2, 6, 9, 7, 0, 7, 6, 2, 8, 9, 3, 5, 0, 2, 0, 1, 0, 4, 4, 0, 1, 7, 3, 9, 5, 6, 0, 2, 6, 4, 1, 7, 0, 8, 0, 2, 9, 0, 2, 9, 0, 4, 9, 9, 3, 3, 8, 8, 2, 7, 8, 8, 8, 1, 9, 1, 8, 6, 3, 5, 0, 5, 9, 2, 1, 4, 8, 7, 9, 8, 6, 0, 0, 5, 1, 9, 9, 6, 3, 0, 2, 8, 5, 6, 1, 5, 4, 3, 1, 9, 3, 0, 3, 8, 9, 9, 4, 0, 2, 5, 6, 0, 6, 3, 3, 8, 8, 4, 0, 4, 9, 1, 4, 1, 4, 4, 9, 6, 2, 6, 9, 5, 9, 4, 1, 4, 8, 8, 0, 6, 7, 0, 4, 2, 5, 3, 2, 8, 1, 4, 0, 6, 3, 1, 9, 6, 2, 5, 5, 9, 9, 2, 9, 3, 9, 0, 3, 5, 1, 0, 7, 3, 5, 9, 9, 1, 6, 4, 4, 2, 0, 2, 7, 0, 8, 5, 6, 6, 3, 2, 6, 4, 5, 6, 7, 2, 1, 3, 5, 8, 7, 3, 5, 3, 8, 2, 9, 8, 5, 0, 9, 8, 3, 3, 1, 4, 0, 1, 0, 0, 9, 4, 3, 5, 9, 8, 4, 8, 8, 0, 5, 3, 4, 5, 1, 2, 2, 8, 0, 5, 0, 5, 9, 0, 9, 1, 7, 2, 0, 4, 0, 6, 9, 2, 8, 3, 3, 0, 8, 2, 8, 3, 9, 7, 6, 2, 7, 2, 3, 9, 2, 4, 0, 9, 0, 1, 2, 8, 3, 8, 5, 3, 1, 2, 1, 4, 8, 8, 3, 7, 2, 9, 8, 4, 1, 1, 9, 6, 1, 2, 4, 4, 1, 9, 5, 4, 9, 2, 8, 7, 4, 2, 7, 2, 5, 0, 8, 7, 0, 1, 2, 5, 0, 9, 7, 8, 0, 4, 7, 5, 8, 1, 2, 8, 4, 8, 0, 6, 4, 0, 9, 8, 4, 1, 2, 8, 4, 6, 1, 8, 3, 8, 7, 3, 2, 0, 2, 9, 1, 8, 6, 6, 0, 5, 0, 7, 5, 1, 2, 6, 2, 3, 3, 8, 0, 6, 0, 9, 2, 4, 1, 1, 1, 3, 0, 3, 4, 0, 6, 5, 7, 0, 5, 4, 5, 8, 3, 9, 7, 7, 3, 5, 9, 6, 6, 4, 3, 8, 4, 5, 0, 7, 0, 5, 5, 7, 3, 4, 1, 8, 7, 3, 3, 6, 3, 5, 7, 1, 1, 4, 7, 0, 2, 7, 3, 7, 3, 3, 8, 5, 0, 9, 6, 0, 8, 8, 2, 9, 4, 7, 6, 6, 1, 3, 0, 6, 9, 7, 2, 1, 3, 0, 0, 0, 4, 4, 7, 9, 7, 2, 1, 8, 4, 5, 9, 9, 9, 6, 9, 9, 4, 6, 7, 7, 2, 8, 5, 8, 7, 3, 3, 9, 9, 1, 2, 7, 8, 7, 8, 8, 1, 4, 9, 0, 4, 1, 9, 0, 6, 0, 1, 7, 0, 7, 2, 8, 9, 2, 2, 6, 2, 9, 2, 8, 2, 5, 4, 7, 3, 0, 6, 7, 2, 9, 4, 1, 7, 6, 0, 8, 5, 7, 2, 5, 2, 1, 3, 8, 3, 7, 3, 3, 7, 9, 4, 1, 5, 2, 5, 3, 8, 1, 3, 5, 4, 7, 9, 1, 1, 1, 9, 0, 8, 2, 3, 4, 2, 2, 8, 4, 6, 7, 4, 3, 5, 2, 5, 6, 7, 1, 1, 3, 2, 1, 5, 6, 6, 4, 4, 7, 8, 6, 0, 5, 4, 9, 7, 0, 9, 8, 2, 1, 6, 7, 3, 2, 0, 8, 2, 5, 3, 3, 1, 6, 3, 5, 6, 2, 5, 3, 8, 3, 7, 2, 2, 3, 9, 1, 9, 4, 5, 9, 1, 8, 3, 8, 4, 7, 7, 4, 2, 6, 7, 9, 7, 2, 5, 2, 1, 2, 9, 2, 3, 8, 0, 0, 8, 0, 1, 0, 0, 6, 0, 1, 2, 3, 3, 9, 2, 6, 8, 1, 6, 7, 8, 0, 5, 7, 2, 4, 6, 7, 2, 3, 6, 9, 7, 8, 4, 3, 2, 2, 6, 2, 0, 0, 6, 8, 9, 5, 1, 5, 1, 3, 7, 0, 1, 9, 6, 8, 7, 9, 5, 3, 4, 5, 3, 8, 5, 1, 4, 0, 8, 5, 4, 6, 6, 4, 6, 8, 3, 6, 1, 6, 4, 7, 0, 9, 3, 8, 7, 2, 0, 6, 6, 9, 6, 0, 9, 9, 6, 6, 7, 2, 8, 0, 0, 3, 4, 1, 2, 1, 7, 9, 1, 9, 1, 9, 3, 2, 6, 6, 3, 8, 7, 9, 8, 1, 4, 4, 6, 5, 5, 2, 1, 6, 9, 1, 0, 0, 8, 9, 7, 9, 9, 4, 7, 9, 8, 0, 2, 5, 6, 0, 2, 9, 2, 4, 9, 2, 4, 6, 6, 0, 3, 5, 8, 7, 3, 1, 2, 3, 3, 6, 2, 7, 9, 4, 3, 5, 5, 2, 4, 5, 2, 2, 9, 5, 5, 2, 2, 6, 8, 9, 0, 7, 0, 7, 5, 4, 8, 8, 3, 0, 9, 2, 0, 9, 6, 0, 7, 8, 5, 0, 1, 7, 8, 6, 2, 2, 9, 2, 8, 0, 1, 0, 3, 7, 3, 9, 4, 0, 3, 5, 5, 9, 6, 2, 8, 9, 5, 9, 0, 4, 8, 1, 0, 5, 7, 4, 5, 5, 1, 8, 8, 6, 3, 8, 9, 0, 5, 5, 4, 8, 0, 6, 5, 2, 6, 1, 3, 7, 1, 8, 8, 6, 4, 8, 0, 3, 2, 5, 2, 6, 0, 8, 8, 5, 8, 4, 5, 7, 9, 4, 1, 2, 2, 2, 1, 6, 5, 2, 8, 5, 7, 7, 5, 2, 3, 8, 0, 5, 0, 0, 8, 2, 9, 7, 0, 6, 8, 0, 6, 8, 4, 2, 1, 1, 1, 5, 4, 1, 5, 9, 8, 1, 8, 0, 9, 7, 3, 8, 0, 3, 0, 7, 4, 9, 9, 2, 8, 5, 7, 1, 3, 1, 0, 0, 5, 3, 6, 7, 8, 1, 6, 4, 8, 6, 4, 7, 6, 9, 3, 9, 2, 3, 1, 9, 2, 2, 2, 7, 2, 9, 9, 7, 3, 2, 6, 8, 9, 7, 6, 5, 5, 1, 3, 8, 2, 7, 2, 4, 7, 3, 6, 1, 1, 1, 5, 9, 7, 1, 9, 6, 6, 4, 0, 5, 4, 8, 1, 8, 2, 7, 5, 7, 2, 7, 8, 0, 5, 9, 3, 0, 6, 9, 1, 5, 5, 4, 9, 9, 1, 5, 7, 8, 6, 5, 5, 1, 2, 0, 2, 1, 3, 6, 5, 4, 4, 4, 9, 3, 3, 9, 2, 0, 3, 6, 5, 6, 1, 7, 0, 5, 6, 0, 1, 2, 4, 0, 3, 7, 4, 5, 0, 5, 0, 0, 8, 0, 1, 3, 6, 2, 1, 8, 0, 3, 2, 1, 5, 0, 0, 9, 9, 6, 3, 4, 0, 8, 4, 7, 3, 4, 1, 0, 8, 1, 9, 2, 0, 0, 0, 3, 6, 2, 5, 4, 5, 9, 8, 1, 0, 8, 2, 1, 8, 8, 1, 2, 3, 7, 3, 6, 9, 3, 0, 4, 8, 1, 2, 2, 1, 3, 2, 6, 2, 1, 8, 9, 4, 2, 9, 8, 4, 7, 8, 6, 5, 5, 4, 5, 2, 2, 2, 1, 6, 7, 1, 9, 5, 8, 2, 1, 1, 8, 6, 2, 5, 5, 0, 8, 0, 0, 5, 5, 6, 4, 3, 9, 1, 4, 6, 2, 4, 0, 1, 9, 8, 9, 4, 0, 6, 9, 0, 4, 7, 0, 5, 1, 4, 4, 9, 0, 5, 0, 4, 1, 7, 0, 6, 8, 2, 3, 1, 6, 8, 3, 2, 2, 8, 1, 2, 4, 4, 9, 8, 5, 1, 7, 1, 7, 3, 4, 9, 1, 5, 4, 1, 0, 3, 2, 7, 2, 4, 7, 6, 0, 3, 8, 8, 1, 1, 5, 0, 3, 2, 8, 4, 3, 4, 5, 4, 4, 2, 1, 2, 2, 8, 0, 8, 5, 6, 7, 2, 1, 8, 1, 2, 9, 7, 6, 7, 6, 6, 4, 0, 0, 2, 3, 5, 0, 2, 2, 8, 9, 8, 8, 4, 3, 9, 3, 6, 1, 9, 2, 4, 7, 7, 6, 8, 3, 9, 7, 5, 6, 5, 0, 7, 9, 6, 7, 2, 9, 3, 9, 8, 5, 8, 0, 8, 6, 2, 7, 6, 9, 8, 3, 2, 2, 1, 1, 1, 8, 6, 9, 5, 6, 5, 8, 5, 0, 6, 9, 5, 0, 4, 4, 5, 5, 5, 8, 0, 0, 9, 2, 9, 9, 0, 1, 4, 8, 4, 0, 1, 9, 0, 1, 0, 9, 1, 0, 7, 8, 5, 2, 5, 0, 8, 3, 5, 7, 2, 7, 5, 0, 8, 5, 0, 7, 5, 4, 1, 6, 5, 3, 3, 9, 6, 7, 8, 4, 7, 0, 4, 0, 6, 7, 4, 2, 8, 2, 1, 9, 6, 8, 0, 6, 1, 6, 0, 2, 7, 5, 2, 8, 4, 7, 6, 2, 0, 2, 6, 1, 7, 6, 2, 2, 7, 0, 3, 8, 3, 4, 2, 9, 1, 1, 1, 7, 3, 2, 4, 1, 9, 4, 3, 9, 2, 3, 7, 5, 9, 0, 5, 1, 4, 4, 4, 2, 6, 6, 6, 0, 2, 3, 2, 8, 3, 0, 7, 3, 7, 7, 2, 3, 0, 0, 5, 2, 0, 2, 4, 6, 8, 4, 5, 6, 9, 1, 3, 1, 8, 1, 0, 2, 8, 8, 1, 6, 2, 6, 0, 9, 2, 2, 7, 3, 1, 3, 0, 5, 0, 4, 9, 6, 9, 6, 3, 1, 7, 5, 1, 6, 5, 1, 5, 2, 8, 9, 0, 7, 9, 0, 3, 2, 0, 9, 1, 2, 5, 9, 9, 7, 3, 6, 5, 4, 0, 2, 0, 6, 4, 4, 3, 7, 2, 6, 5, 0, 3, 2, 1, 1, 9, 1, 2, 7, 0, 7, 9, 7, 6, 0, 9, 6, 1, 2, 9, 3, 4, 5, 6, 2, 2, 8, 8, 8, 6, 7, 3, 8, 5, 4, 9, 4, 1, 6, 4, 5, 3, 2, 7, 0, 7, 4, 7, 9, 1, 0, 7, 5, 0, 4, 9, 9, 1, 7, 7, 8, 7, 6, 0, 4, 1, 7, 2, 4, 0, 1, 0, 0, 3, 3, 9, 2, 1, 8, 6, 0, 1, 5, 2, 1, 4, 0, 2, 7, 3, 9, 8, 9, 3, 9, 6, 2, 1, 1, 1, 1, 3, 3, 1, 5, 6, 2, 5, 7, 0, 9, 0, 5, 6, 5, 4, 9, 0, 7, 0, 6, 9, 5, 8, 3, 4, 2, 2, 3, 4, 9, 9, 2, 5, 9, 1, 3, 0, 2, 2, 9, 3, 8, 2, 8, 2, 2, 3, 6, 6, 2, 8, 3, 1, 4, 5, 0, 1, 2, 6, 5, 9, 7, 4, 7, 1, 0, 0, 6, 0, 5, 7, 2, 3, 5, 9, 0, 3, 3, 9, 9, 9, 2, 0, 8, 9, 9, 7, 0, 8, 2, 5, 6, 4, 8, 4, 2, 3, 8, 2, 1, 6, 7, 1, 8, 5, 7, 0, 6, 5, 2, 3, 9, 0, 0, 7, 3, 9, 2, 4, 9, 4, 2, 4, 2, 9, 4, 6, 2, 1, 2, 5, 5, 3, 1, 6, 2, 4, 0, 7, 9, 8, 4, 2, 0, 0, 0, 1, 3, 0, 6, 9, 2, 9, 2, 2, 7, 1, 5, 2, 9, 5, 0, 1, 0, 9, 3, 7, 4, 0, 4, 5, 7, 0, 2, 0, 3, 6, 7, 2, 6, 5, 3, 4, 3, 0, 6, 9, 9, 0, 1, 1, 0, 6, 2, 2, 2, 8, 0, 9, 6, 4, 5, 6, 6, 1, 1, 4, 6, 9, 1, 9, 0, 6, 2, 6, 4, 4, 8, 3, 2, 2, 8, 9, 6, 9, 8, 4, 7, 5, 7, 2, 3, 6, 3, 7, 4, 4, 5, 0, 8, 5, 7, 4, 0, 8, 4, 2, 0, 2, 1, 5, 2, 8, 1, 8, 8, 3, 2, 2, 8, 5, 1, 8, 4, 7, 9, 4, 0, 5, 3, 6, 9, 6, 1, 7, 2, 3, 4, 4, 5, 3, 2, 0, 3, 4, 7, 6, 5, 0, 4, 4, 9, 2, 9, 2, 1, 7, 0, 9, 2, 0, 6, 7, 5, 7, 0, 1, 9, 1, 5, 7, 5, 8, 6, 4, 4, 2, 9, 0, 4, 2, 2, 8, 7, 3, 5, 5, 6, 4, 2, 6, 7, 9, 7, 7, 6, 0, 4, 2, 3, 3, 1, 0, 7, 1, 6, 0, 5, 9, 6, 6, 1, 3, 6, 3, 4, 5, 8, 8, 1, 1, 5, 0, 9, 4, 0, 9, 0, 8, 1, 2, 1, 4, 8, 7, 9, 4, 0, 1, 3, 2, 0, 2, 8, 2, 4, 5, 1, 7, 9, 1, 8, 8, 0, 7, 0, 6, 7, 4, 1, 5, 7, 0, 3, 7, 5, 1, 3, 4, 9, 6, 8, 7, 3, 3, 4, 5, 7, 0, 7, 2, 3, 3, 7, 7, 2, 1, 7, 3, 0, 7, 8, 3, 1, 9, 9, 0, 1, 7, 5, 2, 2, 2, 6, 8, 3, 7, 2, 3, 7, 6, 3, 2, 3, 2, 0, 0, 6, 1, 4, 2, 4, 2, 3, 4, 0, 2, 0, 6, 6, 3, 0, 0, 3, 1, 2, 1, 0, 4, 5, 3, 8, 3, 0, 1, 5, 0, 0, 7, 9, 9, 9, 9, 9, 2, 0, 8, 4, 6, 9, 2, 5, 5, 4, 9, 1, 7, 1, 9, 9, 7, 0, 4, 2, 0, 3, 5, 0, 0, 5, 4, 5, 1, 8, 5, 7, 3, 0, 0, 4, 4, 9, 0, 1, 0, 6, 0, 8, 6, 9, 4, 3, 8, 1, 4, 0, 8, 1, 3, 8, 4, 8, 0, 0, 2, 0, 7, 7, 9, 2, 6, 1, 2, 5, 4, 6, 9, 2, 1, 4, 0, 9, 2, 9, 9, 3, 5, 0, 5, 1, 8, 1, 2, 5, 8, 2, 3, 9, 5, 2, 1, 9, 0, 9, 7, 8, 2, 3, 8, 5, 7, 0, 2, 4, 9, 0, 7, 0, 9, 4, 6, 3, 7, 1, 5, 6, 4, 3, 5, 3, 5, 6, 2, 0, 5, 2, 2, 4, 3, 0, 2, 3, 9, 7, 5, 8, 8, 9, 6, 8, 4, 5, 8, 3, 5, 6, 8, 1, 2, 2, 4, 5, 7, 1, 0, 9, 4, 4, 2, 3, 9, 4, 7, 2, 9, 8, 9, 4, 7, 8, 6, 2, 9, 7, 1, 0, 0, 2, 3, 9, 4, 8, 7, 3, 3, 8, 2, 1, 7, 6, 7, 3, 8, 5, 8, 9, 5, 3, 5, 0, 7, 9, 4, 6, 0, 4, 7, 7, 8, 5, 2, 3, 4, 6, 0, 6, 4, 3, 2, 9, 9, 5, 3, 1, 5, 7, 3, 0, 4, 5, 1, 6, 9, 2, 8, 5, 1, 3, 2, 6, 6, 7, 2, 5, 8, 1, 9, 8, 8, 8, 2, 6, 8, 1, 6, 7, 9, 4, 7, 7, 4, 5, 0, 5, 8, 8, 5, 8, 9, 3, 0, 0, 1, 1, 4, 2, 1, 1, 6, 7, 8, 8, 3, 2, 2, 2, 6, 8, 3, 0, 9, 5, 0, 4, 7, 8, 6, 1, 9, 9, 0, 4, 2, 0, 6, 3, 5, 1, 0, 7, 6, 2, 1, 7, 2, 5, 7, 0, 8, 1, 6, 9, 0, 6, 6, 0, 7, 0, 9, 9, 6, 0, 5, 9, 2, 1, 3, 0, 4, 8, 2, 5, 8, 6, 9, 1, 6, 4, 7, 2, 6, 8, 2, 6, 3, 3, 9, 9, 9, 6, 1, 0, 1, 4, 4, 7, 7, 6, 3, 3, 9, 8, 9, 7, 1, 8, 9, 1, 6, 0, 7, 8, 8, 7, 8, 7, 5, 1, 9, 4, 1, 1, 6, 5, 2, 2, 8, 9, 1, 9, 8, 8, 1, 1, 7, 7, 9, 0, 1, 3, 8, 5, 8, 1, 9, 0, 5, 8, 5, 0, 7, 3, 3, 4, 2, 4, 7, 7, 2, 6, 0, 4, 4, 8, 3, 1, 8, 4, 0, 6, 0, 4, 0, 6, 0, 7, 7, 1, 0, 6, 3, 2, 5, 2, 5, 8, 1, 8, 8, 3, 0, 3, 2, 7, 2, 0, 3, 8, 1, 9, 3, 0, 9, 8, 1, 1, 4, 4, 3, 3, 2, 9, 0, 4, 3, 8, 7, 9, 7, 8, 4, 7, 2, 9, 0, 1, 3, 0, 7, 2, 0, 1, 8, 9, 6, 1, 1, 0, 5, 7, 6, 4, 5, 7, 3, 0, 4, 3, 9, 9, 1, 7, 4, 4, 9, 2, 3, 3, 2, 7, 6, 9, 9, 5, 3, 4, 3, 7, 3, 1, 1, 0, 4, 2, 9, 3, 6, 3, 5, 1, 7, 3, 5, 2, 2, 3, 7, 9, 3, 4, 6, 7, 5, 3, 0, 9, 2, 0, 7, 7, 3, 2, 7, 6, 8, 6, 0, 2, 2, 9, 5, 9, 2, 1, 5, 1, 7, 2, 5, 7, 1, 5, 7, 7, 7, 4, 1, 1, 7, 0, 3, 4, 5, 2, 1, 1, 5, 1, 8, 3, 7, 3, 7, 1, 8, 5, 7, 6, 2, 9, 8, 0, 4, 6, 1, 5, 3, 2, 2, 8, 8, 0, 0, 7, 8, 9, 2, 0, 5, 7, 5, 7, 5, 7, 2, 3, 8, 4, 2, 3, 6, 3, 8, 4, 5, 2, 2, 6, 7, 2, 7, 3, 2, 3, 7, 4, 0, 7, 9, 9, 1, 8, 8, 4, 2, 2, 3, 0, 8, 9, 3, 1, 1, 1, 5, 4, 9, 2, 6, 0, 4, 9, 2, 9, 0, 5, 5, 2, 9, 3, 7, 7, 5, 5, 4, 4, 5, 7, 7, 6, 3, 7, 9, 9, 3, 8, 3, 4, 2, 9, 4, 3, 9, 5, 0, 1, 8, 0, 4, 0, 6, 7, 9, 2, 6, 9, 9, 8, 2, 8, 8, 4, 3, 1, 3, 7, 0, 4, 8, 3, 9, 1, 3, 4, 8, 6, 0, 0, 0, 7, 3, 4, 3, 2, 3, 2, 5, 4, 6, 6, 4, 0, 4, 9, 2, 9, 1, 0, 8, 0, 7, 4, 1, 7, 3, 2, 9, 0, 5, 8, 8, 8, 0, 1, 4, 2, 6, 2, 8, 1, 5, 8, 8, 0, 0, 4, 7, 9, 3, 6, 7, 5, 4, 7, 0, 7, 7, 5, 7, 4, 0, 0, 6, 5, 0, 6, 2, 1, 0, 7, 3, 5, 9, 4, 0, 7, 1, 3, 9, 6, 0, 1, 9, 6, 9, 8, 3, 8, 5, 2, 7, 0, 7, 6, 8, 9, 9, 9, 1, 1, 2, 1, 5, 7, 7, 6, 1, 0, 4, 3, 7, 9, 0, 4, 1, 2, 7, 1, 4, 9, 8, 6, 5, 6, 7, 4, 1, 6, 9, 8, 7, 3, 4, 1, 1, 0, 9, 5, 7, 8, 6, 5, 0, 1, 2, 4, 0, 3, 4, 0, 3, 7, 1, 8, 2, 2, 2, 1, 7, 7, 7, 6, 5, 8, 9, 7, 1, 6, 3, 2, 5, 1, 2, 8, 4, 1, 4, 6, 4, 5, 6, 3, 5, 2, 9, 3, 0, 6, 4, 2, 3, 6, 4, 1, 4, 8, 2, 1, 2, 6, 8, 2, 8, 5, 1, 1, 9, 4, 1, 0, 9, 4, 4, 6, 5, 0, 6, 7, 3, 2, 9, 1, 8, 5, 0, 3, 2, 5, 9, 4, 7, 8, 0, 4, 0, 5, 1, 1, 2, 7, 1, 3, 1, 7, 7, 2, 2, 3, 6, 4, 7, 5, 2, 8, 3, 9, 2, 3, 2, 9, 1, 6, 9, 0, 0, 0, 1, 8, 1, 4, 1, 4, 7, 8, 8, 1, 5, 2, 5, 1, 1, 2, 2, 5, 8, 1, 8, 2, 4, 9, 4, 8, 5, 1, 9, 5, 8, 9, 0, 4, 0, 3, 5, 4, 0, 2, 1, 4, 9, 1, 5, 5, 3, 4, 0, 9, 1, 8, 8, 9, 4, 3, 3, 7, 9, 3, 9, 4, 5, 3, 9, 2, 9, 0, 9, 9, 0, 4, 3, 7, 4, 0, 6, 0, 5, 0, 1, 4, 8, 2, 3, 8, 2, 9, 8, 5, 2, 9, 7, 5, 9, 1, 5, 5, 8, 9, 1, 0, 7, 4, 7, 2, 1, 1, 0, 3, 1, 6, 4, 9, 4, 4, 5, 0, 5, 6, 5, 2, 9, 1, 7, 6, 3, 5, 2, 0, 4, 6, 0, 1, 9, 8, 6, 1, 2, 6, 9, 0, 3, 4, 5, 8, 0, 7, 6, 1, 3, 5, 8, 6, 7, 0, 6, 9, 2, 3, 8, 0, 1, 5, 9, 2, 4, 7, 2, 4, 7, 2, 2, 4, 1, 0, 0, 3, 9, 8, 5, 2, 8, 7, 6, 5, 4, 0, 6, 8, 9, 0, 2, 5, 2, 3, 0, 4, 7, 2, 6, 2, 6, 9, 5, 0, 8, 1, 1, 2, 2, 4, 7, 8, 8, 4, 5, 3, 3, 6, 6, 1, 6, 3, 4, 6, 5, 6, 1, 4, 2, 4, 6, 0, 7, 6, 3, 2, 7, 8, 0, 9, 8, 2, 5, 9, 0, 7, 7, 6, 1, 7, 2, 3, 9, 8, 6, 1, 2, 4, 4, 5, 4, 1, 6, 8, 5, 2, 7, 1, 0, 9, 8, 3, 4, 2, 0, 0, 9, 5, 8, 5, 1, 5, 5, 5, 0, 9, 6, 3, 3, 7, 3, 1, 1, 1, 2, 8, 0, 8, 0, 3, 9, 9, 0, 1, 6, 4, 7, 0, 7, 7, 2, 5, 5, 8, 2, 2, 0, 0, 0, 6, 3, 2, 0, 5, 6, 4, 5, 2, 4, 0, 7, 1, 3, 0, 8, 0, 4, 1, 8, 1, 8, 6, 3, 4, 0, 3, 3, 6, 5, 4, 8, 1, 7, 8, 5, 6, 2, 7, 1, 6, 7, 4, 5, 5, 2, 2, 8, 1, 4, 2, 1, 6, 4, 4, 8, 5, 7, 9, 3, 5, 7, 7, 3, 9, 4, 9, 5, 7, 8, 3, 0, 4, 9, 7, 3, 9, 0, 3, 3, 0, 2, 0, 0, 5, 2, 3, 2, 6, 2, 2, 5, 9, 2, 5, 6, 9, 1, 6, 2, 3, 1, 0, 4, 6, 7, 5, 7, 4, 6, 4, 3, 7, 7, 5, 5, 4, 6, 8, 5, 0, 1, 0, 4, 5, 3, 3, 7, 4, 1, 0, 3, 6, 7, 2, 1, 2, 5, 7, 9, 5, 6, 5, 9, 1, 6, 9, 2, 8, 2, 9, 7, 8, 7, 9, 0, 8, 7, 7, 3, 3, 1, 6, 0, 8, 5, 1, 5, 5, 7, 0, 1, 6, 9, 5, 4, 3, 2, 4, 4, 8, 0, 3, 4, 5, 0, 5, 4, 0, 7, 7, 7, 9, 2, 0, 2, 4, 9, 3, 8, 5, 7, 3, 4, 3, 3, 2, 3, 2, 8, 2, 8, 7, 7, 1, 3, 6, 9, 3, 1, 9, 3, 1, 1, 0, 8, 0, 9, 0, 5, 9, 6, 2, 5, 2, 2, 2, 0, 2, 4, 4, 1, 1, 0, 4, 9, 8, 0, 4, 7, 2, 6, 6, 1, 5, 0, 3, 7, 0, 4, 1, 4, 7, 7, 4, 9, 0, 0, 7, 9, 3, 0, 1, 5, 4, 6, 8, 9, 2, 5, 0, 4, 4, 2, 1, 9, 0, 6, 2, 3, 3, 6, 6, 9, 9, 8, 7, 3, 6, 3, 9, 0, 7, 1, 8, 5, 2, 5, 0, 1, 6, 8, 3, 3, 8, 4, 2, 7, 3, 3, 5, 0, 2, 7, 3, 5, 2, 7, 2, 6, 4, 3, 0, 1, 8, 7, 8, 7, 3, 8, 8, 3, 3, 0, 5, 2, 7, 7, 1, 6, 8, 6, 2, 5, 0, 1, 6, 7, 0, 3, 3, 1, 9, 2, 0, 3, 4, 5, 9, 1, 5, 2, 6, 3, 1, 6, 6, 6, 1, 3, 0, 7, 4, 2, 7, 5, 2, 9, 2, 2, 3, 2, 9, 8, 7, 7, 8, 4, 1, 6, 8, 0, 0, 4, 6, 7, 7, 4, 7, 4, 2, 0, 0, 5, 2, 6, 2, 1, 7, 0, 5, 9, 9, 1, 1, 0, 3, 1, 2, 3, 1, 6, 7, 0, 5, 7, 8, 8, 4, 0, 7, 6, 8, 7, 8, 2, 0, 7, 2, 2, 5, 2, 1, 0, 1, 0, 2, 0, 4, 9, 3, 6, 3, 8, 2, 4, 6, 6, 5, 6, 8, 3, 6, 2, 5, 5, 0, 7, 8, 0, 2, 5, 7, 7, 6, 0, 7, 6, 5, 2, 8, 8, 3, 7, 4, 8, 2, 5, 7, 4, 4, 8, 3, 5, 5, 1, 8, 0, 9, 6, 0, 1, 1, 0, 9, 5, 4, 7, 5, 5, 8, 1, 5, 1, 3, 3, 5, 7, 6, 5, 3, 8, 4, 4, 3, 8, 4, 9, 5, 3, 7, 6, 4, 0, 2, 9, 7, 5, 9, 0, 3, 2, 0, 9, 4, 0, 8, 0, 2, 0, 0, 8, 9, 5, 0, 0, 3, 7, 6, 6, 9, 3, 2, 6, 9, 9, 4, 8, 4, 5, 2, 4, 1, 4, 6, 6, 0, 9, 8, 8, 6, 2, 9, 8, 8, 7, 7, 0, 1, 8, 4, 3, 5, 4, 8, 1, 8, 1, 2, 0, 3, 7, 4, 7, 0, 0, 9, 7, 1, 1, 8, 7, 1, 0, 6, 0, 8, 8, 7, 1, 7, 4, 4, 3, 4, 6, 2, 1, 0, 4, 5, 5, 1, 4, 6, 8, 6, 8, 1, 4, 0, 8, 8, 2, 5, 8, 0, 5, 0, 4, 5, 9, 5, 5, 7, 2, 9, 6, 2, 2, 1, 7, 8, 6, 6, 1, 3, 0, 2, 3, 7, 9, 0, 1, 7, 3, 2, 8, 7, 1, 2, 4, 0, 8, 6, 3, 9, 0, 4, 5, 1, 9, 3, 4, 5, 8, 1, 8, 0, 7, 3, 9, 5, 6, 0, 0, 0, 8, 5, 3, 0, 4, 7, 0, 3, 3, 6, 9, 6, 5, 2, 4, 9, 1, 3, 4, 4, 2, 2, 9, 9, 1, 2, 2, 9, 1, 2, 7, 9, 5, 0, 2, 6, 8, 0, 6, 9, 1, 8, 5, 8, 4, 0, 6, 8, 8, 7, 9, 4, 7, 2, 0, 4, 9, 3, 5, 2, 5, 1, 4, 3, 4, 6, 1, 4, 1, 2, 7, 4, 7, 8, 4, 3, 0, 0, 3, 5, 0, 6, 0, 0, 2, 6, 3, 2, 5, 1, 7, 4, 8, 8, 9, 0, 8, 3, 6, 2, 0, 6, 0, 7, 2, 1, 7, 2, 2, 9, 8, 5, 3, 7, 4, 0, 8, 3, 7, 9, 4, 3, 6, 8, 7, 4, 8, 7, 8, 1, 7, 7, 5, 8, 8, 8, 4, 8, 1, 7, 2, 6, 4, 5, 2, 1, 5, 8, 7, 6, 4, 2, 4, 3, 8, 5, 8, 2, 1, 7, 5, 0, 4, 0, 0, 2, 0, 6, 9, 3, 5, 2, 0, 0, 6, 0, 1, 9, 0, 2, 0, 7, 6, 6, 9, 9, 2, 1, 1, 7, 9, 4, 2, 9, 9, 4, 1, 2, 5, 4, 5, 4, 0, 5, 9, 9, 8, 9, 6, 2, 9, 8, 0, 6, 0, 2, 6, 9, 4, 3, 7, 6, 2, 7, 0, 1, 0, 3, 7, 5, 6, 0, 7, 9, 5, 2, 3, 9, 6, 7, 6, 8, 5, 0, 2, 2, 2, 5, 3, 7, 4, 5, 4, 1, 1, 4, 6, 8, 1, 5, 2, 3, 9, 3, 1, 3, 5, 0, 4, 7, 4, 1, 4, 3, 7, 4, 0, 3, 3, 8, 5, 3, 0, 0, 7, 9, 9, 6, 6, 4, 4, 2, 0, 7, 0, 7, 0, 6, 4, 3, 2, 6, 2, 2, 2, 2, 6, 0, 7, 6, 7, 6, 4, 0, 9, 9, 2, 8, 8, 3, 6, 6, 9, 4, 1, 7, 1, 1, 0, 3, 5, 5, 0, 3, 7, 1, 5, 1, 8, 8, 4, 1, 7, 1, 6, 6, 0, 2, 4, 0, 2, 8, 0, 9, 3, 4, 7, 0, 6, 7, 0, 7, 1, 3, 5, 8, 0, 4, 5, 9, 7, 9, 4, 8, 1, 3, 7, 3, 3, 5, 9, 5, 9, 5, 6, 7, 8, 8, 3, 9, 5, 0, 8, 9, 4, 1, 7, 1, 0, 9, 9, 1, 9, 8, 0, 3, 1, 6, 1, 0, 6, 0, 9, 9, 6, 2, 9, 2, 1, 3, 1, 7, 2, 8, 7, 2, 0, 5, 2, 8, 8, 9, 9, 9, 3, 3, 0, 1, 7, 8, 6, 2, 9, 0, 9, 5, 5, 4, 9, 8, 5, 8, 0, 4, 4, 6, 5, 5, 7, 9, 5, 5, 5, 0, 6, 9, 3, 1, 0, 8, 7, 7, 6, 9, 0, 4, 5, 7, 9, 7, 3, 9, 6, 2, 8, 4, 7, 5, 1, 3, 7, 7, 7, 8, 9, 5, 9, 9, 3, 6, 6, 3, 7, 9, 4, 5, 1, 8, 9, 2, 5, 0, 8, 6, 4, 9, 4, 3, 3, 2, 9, 7, 2, 2, 1, 8, 4, 0, 8, 7, 1, 0, 3, 1, 2, 3, 3, 2, 6, 2, 2, 3, 2, 3, 5, 5, 8, 3, 0, 1, 6, 2, 5, 8, 6, 1, 9, 2, 9, 1, 8, 9, 6, 6, 8, 9, 3, 1, 9, 3, 8, 2, 0, 7, 0, 7, 3, 6, 3, 8, 9, 4, 5, 4, 7, 2, 7, 2, 4, 5, 6, 0, 6, 2, 9, 7, 9, 4, 6, 1, 7, 6, 2, 3, 4, 2, 9, 9, 8, 6, 8, 6, 0, 2, 7, 4, 1, 9, 7, 3, 8, 7, 6, 7, 5, 6, 1, 2, 4, 3, 8, 6, 3, 5, 3, 4, 5, 8, 0, 5, 2, 0, 4, 4, 4, 3, 1, 6, 8, 1, 2, 7, 5, 6, 4, 2, 0, 3, 0, 0, 6, 2, 1, 6, 9, 1, 3, 3, 4, 2, 3, 2, 9, 2, 4, 0, 6, 5, 6, 6, 0, 2, 1, 7, 3, 0, 5, 6, 7, 3, 1, 3, 6, 9, 5, 6, 7, 5, 3, 5, 4, 3, 3, 0, 1, 6, 9, 3, 1, 9, 5, 1, 3, 4, 1, 2, 5, 2, 8, 9, 8, 8, 0, 7, 1, 5, 7, 9, 2, 0, 5, 2, 7, 0, 6, 0, 3, 1, 0, 7, 7, 7, 5, 9, 9, 9, 7, 2, 0, 4, 6, 0, 2, 8, 0, 0, 2, 8, 0, 2, 3, 3, 6, 2, 1, 8, 4, 0, 2, 1, 3, 7, 4, 3, 3, 9, 1, 0, 6, 4, 1, 0, 8, 7, 8, 9, 5, 8, 8, 0, 6, 5, 2, 0, 6, 5, 2, 9, 9, 5, 6, 9, 0, 7, 3, 1, 8, 8, 7, 1, 9, 4, 4, 7, 7, 9, 8, 3, 2, 2, 2, 7, 7, 1, 4, 5, 7, 1, 7, 2, 2, 2, 3, 1, 8, 7, 6, 3, 2, 1, 6, 2, 0, 3, 9, 9, 3, 1, 9, 3, 7, 4, 5, 6, 9, 4, 0, 2, 3, 6, 0, 8, 8, 2, 5, 4, 1, 7, 7, 9, 3, 5, 4, 7, 4, 0, 9, 0, 6, 2, 2, 8, 1, 5, 4, 6, 7, 0, 0, 1, 5, 9, 0, 4, 3, 7, 8, 2, 0, 8, 6, 9, 2, 2, 2, 6, 6, 4, 2, 0, 5, 1, 9, 9, 5, 4, 6, 3, 7, 1, 3, 3, 3, 2, 5, 1, 8, 5, 0, 1, 5, 1, 4, 3, 9, 4, 8, 1, 7, 9, 7, 0, 8, 7, 4, 0, 0, 9, 3, 6, 1, 6, 5, 8, 4, 0, 3, 5, 5, 8, 3, 6, 7, 3, 8, 6, 8, 9, 1, 8, 2, 5, 6, 2, 4, 3, 5, 0, 8, 7, 6, 1, 9, 2, 4, 1, 7, 1, 9, 7, 5, 0, 8, 0, 6, 2, 6, 8, 7, 6, 6, 1, 7, 2, 2, 2, 3, 2, 6, 9, 8, 1, 3, 0, 2, 1, 7, 9, 3, 6, 2, 2, 9, 7, 9, 6, 5, 3, 0, 2, 5, 0, 7, 1, 5, 9, 9, 8, 3, 7, 1, 4, 7, 8, 7, 0, 0, 7, 3, 3, 3, 1, 3, 4, 3, 4, 3, 0, 2, 3, 0, 3, 8, 7, 0, 5, 0, 2, 5, 9, 3, 9, 0, 4, 5, 2, 3, 2, 4, 6, 9, 8, 7, 5, 5, 1, 5, 8, 5, 2, 9, 7, 9, 2, 4, 0, 7, 9, 7, 4, 7, 6, 2, 3, 0, 3, 4, 4, 2, 1, 9, 0, 4, 7, 0, 7, 4, 6, 1, 9, 8, 4, 8, 2, 0, 6, 7, 0, 0, 0, 9, 5, 4, 1, 8, 9, 3, 8, 7, 3, 8, 2, 5, 0, 8, 1, 4, 8, 4, 8, 9, 6, 8, 3, 4, 6, 2, 7, 7, 5, 8, 3, 1, 1, 2, 7, 1, 9, 2, 0, 4, 6, 4, 3, 8, 9, 2, 5, 5, 9, 2, 8, 5, 4, 1, 1, 8, 7, 8, 4, 3, 0, 9, 9, 4, 2, 5, 3, 8, 3, 8, 8, 1, 5, 2, 5, 8, 7, 5, 5, 2, 8, 4, 4, 0, 2, 1, 6, 2, 1, 9, 8, 9, 2, 3, 7, 7, 7, 6, 5, 0, 1, 5, 9, 0, 7, 9, 8, 7, 4, 3, 8, 7, 5, 0, 2, 1, 0, 9, 4, 1, 4, 0, 1, 8, 7, 4, 0, 9, 3, 7, 4, 4, 2, 6, 8, 1, 1, 5, 3, 1, 2, 2, 9, 5, 6, 8, 4, 4, 4, 7, 1, 1, 4, 2, 1, 3, 9, 4, 0, 8, 9, 1, 6, 6, 2, 4, 7, 9, 6, 4, 0, 7, 3, 9, 0, 1, 7, 9, 9, 4, 3, 0, 6, 8, 3, 5, 0, 4, 3, 5, 1, 6, 1, 1, 3, 8, 5, 9, 0, 7, 2, 5, 1, 0, 5, 6, 2, 5, 4, 7, 5, 2, 2, 6, 2, 9, 5, 5, 0, 0, 8, 4, 4, 9, 6, 1, 1, 9, 9, 2, 6, 6, 2, 0, 8, 3, 5, 5, 6, 2, 6, 1, 5, 3, 2, 9, 7, 6, 0, 5, 2, 7, 9, 6, 3, 5, 2, 2, 0, 6, 7, 3, 0, 7, 5, 4, 1, 1, 6, 4, 5, 4, 3, 2, 7, 0, 4, 9, 9, 7, 5, 9, 5, 1, 4, 6, 9, 4, 8, 7, 6, 1, 2, 7, 2, 1, 0, 7, 9, 8, 8, 3, 0, 4, 2, 5, 5, 0, 0, 1, 9, 3, 1, 3, 8, 1, 1, 5, 0, 6, 7, 1, 7, 1, 4, 8, 0, 7, 7, 6, 1, 4, 2, 6, 0, 1, 5, 2, 8, 2, 0, 7, 8, 0, 5, 8, 5, 6, 5, 7, 3, 3, 8, 3, 2, 1, 6, 9, 7, 4, 4, 4, 0, 0, 0, 3, 4, 0, 2, 5, 3, 4, 0, 4, 3, 6, 5, 4, 8, 8, 0, 1, 4, 7, 3, 9, 9, 4, 8, 2, 2, 6, 8, 2, 4, 0, 0, 2, 4, 2, 9, 7, 6, 3, 2, 0, 1, 2, 4, 0, 8, 4, 6, 2, 5, 3, 8, 9, 4, 9, 9, 7, 7, 7, 1, 9, 3, 6, 5, 8, 5, 8, 7, 8, 8, 9, 4, 6, 4, 6, 9, 8, 3, 9, 2, 7, 8, 4, 3, 0, 2, 2, 1, 6, 2, 9, 4, 3, 7, 2, 9, 0, 9, 7, 3, 1, 6, 3, 4, 2, 8, 1, 5, 4, 8, 9, 4, 9, 4, 3, 6, 0, 5, 4, 8, 3, 6, 1, 0, 2, 9, 4, 4, 5, 4, 0, 9, 1, 7, 2, 9, 2, 3, 7, 4, 0, 0, 0, 2, 2, 8, 1, 3, 6, 4, 6, 4, 4, 7, 3, 4, 2, 9, 2, 1, 1, 0, 8, 0, 3, 8, 4, 4, 1, 0, 3, 8, 1, 1, 0, 7, 1, 5, 5, 2, 0, 5, 9, 1, 5, 5, 6, 2, 3, 7, 0, 1, 9, 6, 2, 3, 0, 1, 7, 3, 9, 7, 3, 8, 6, 0, 2, 5, 7, 0, 1, 2, 7, 4, 2, 8, 5, 7, 2, 7, 2, 0, 0, 5, 0, 6, 8, 8, 1, 8, 3, 7, 9, 1, 9, 2, 0, 4, 2, 1, 3, 9, 2, 4, 0, 6, 2, 4, 0, 7, 5, 7, 2, 8, 8, 9, 9, 7, 3, 7, 6, 7, 9, 4, 0, 1, 1, 7, 0, 7, 8, 2, 8, 1, 6, 6, 9, 1, 8, 3, 1, 7, 6, 4, 3, 5, 5, 7, 4, 1, 7, 3, 3, 0, 7, 8, 3, 0, 1, 9, 5, 5, 2, 7, 0, 2, 9, 9, 3, 9, 2, 1, 6, 1, 1, 0, 7, 3, 0, 5, 8, 8, 0, 0, 0, 5, 0, 7, 6, 1, 2, 9, 9, 2, 9, 2, 5, 0, 7, 5, 6, 1, 1, 1, 8, 3, 2, 0, 0, 3, 5, 9, 9, 3, 2, 7, 7, 1, 1, 5, 6, 7, 0, 0, 0, 6, 8, 1, 5, 5, 4, 9, 0, 2, 5, 9, 6, 4, 9, 2, 4, 8, 2, 4, 5, 3, 1, 0, 5, 3, 5, 1, 7, 7, 7, 7, 7, 4, 6, 7, 3, 3, 3, 0, 4, 9, 6, 6, 7, 8, 6, 7, 0, 1, 6, 7, 2, 0, 0, 9, 3, 9, 2, 4, 9, 7, 0, 0, 9, 4, 0, 7, 3, 5, 3, 1, 1, 2, 7, 1, 5, 6, 2, 5, 5, 4, 4, 8, 3, 0, 0, 4, 8, 0, 9, 4, 0, 2, 5, 4, 6, 1, 8, 5, 4, 1, 2, 4, 5, 3, 8, 0, 4, 9, 1, 1, 8, 2, 9, 5, 1, 2, 5, 0, 0, 0, 0, 7, 0, 8, 0, 5, 7, 4, 7, 4, 2, 5, 6, 9, 8, 1, 2, 1, 2, 3, 4, 0, 8, 8, 9, 4, 2, 7, 1, 7, 7, 1, 7, 3, 8, 8, 4, 0, 7, 7, 5, 9, 9, 1, 9, 2, 6, 4, 8, 2, 5, 4, 7, 0, 2, 0, 1, 4, 4, 4, 3, 8, 7, 5, 9, 4, 5, 9, 2, 1, 1, 3, 0, 7, 7, 8, 8, 0, 4, 0, 3, 6, 8, 5, 8, 2, 6, 2, 5, 5, 6, 9, 9, 7, 3, 0, 0, 9, 6, 0, 0, 6, 9, 7, 3, 0, 6, 9, 8, 6, 0, 1, 4, 4, 5, 8, 4, 4, 8, 7, 0, 5, 4, 9, 5, 9, 5, 4, 5, 4, 2, 4, 2, 0, 6, 2, 1, 7, 2, 6, 1, 8, 3, 7, 2, 1, 8, 5, 2, 1, 8, 1, 5, 3, 1, 6, 5, 7, 2, 7, 2, 6, 7, 0, 2, 4, 2, 6, 1, 5, 3, 1, 7, 3, 4, 3, 3, 1, 0, 4, 3, 1, 0, 8, 4, 9, 2, 0, 7, 2, 5, 8, 9, 5, 5, 3, 0, 3, 4, 0, 5, 7, 6, 1, 5, 3, 9, 7, 6, 6, 0, 5, 1, 5, 2, 9, 0, 8, 8, 0, 7, 1, 8, 4, 5, 3, 3, 5, 5, 8, 9, 3, 9, 0, 7, 2, 9, 7, 2, 8, 6, 8, 3, 0, 4, 0, 4, 4, 5, 5, 7, 8, 5, 2, 5, 6, 6, 3, 0, 0, 1, 2, 0, 3, 0, 7, 7, 4, 5, 0, 1, 4, 3, 9, 3, 4, 0, 7, 0, 9, 9, 6, 8, 0, 5, 7, 9, 5, 7, 8, 6, 2, 2, 0, 4, 1, 2, 5, 4, 5, 3, 9, 8, 5, 1, 5, 4, 9, 6, 3, 8, 8, 6, 2, 5, 2, 4, 5, 9, 7, 9, 5, 0, 9, 7, 8, 3, 7, 7, 1, 0, 6, 7, 9, 4, 5, 9, 8, 1, 0, 8, 5, 2, 8, 0, 4, 4, 5, 1, 6, 1, 3, 5, 8, 6, 9, 3, 8, 3, 6, 9, 1, 2, 3, 4, 7, 8, 3, 3, 5, 8, 3, 5, 7, 2, 8, 5, 1, 0, 5, 1, 7, 0, 2, 0, 4, 4, 2, 1, 6, 8, 3, 4, 5, 0, 5, 8, 4, 1, 6, 5, 9, 2, 2, 9, 6, 1, 8, 4, 7, 8, 9, 7, 8, 1, 1, 3, 1, 7, 7, 0, 3, 7, 6, 9, 7, 6, 3, 7, 2, 2, 1, 7, 7, 3, 9, 5, 5, 9, 1, 1, 6, 7, 2, 2, 4, 3, 6, 6, 2, 1, 7, 9, 4, 5, 4, 7, 1, 2, 0, 0, 8, 0, 8, 5, 7, 5, 2, 7, 0, 4, 5, 5, 7, 4, 4, 9, 0, 2, 3, 2, 3, 0, 3, 4, 6, 7, 9, 9, 5, 0, 0, 8, 9, 9, 3, 4, 4, 2, 2, 3, 2, 7, 3, 4, 5, 9, 7, 9, 9, 3, 4, 9, 9, 5, 4, 2, 1, 7, 6, 0, 3, 5, 7, 0, 4, 1, 9, 7, 2, 9, 9, 8, 2, 9, 6, 5, 7, 0, 9, 7, 1, 3, 6, 0, 4, 9, 4, 1, 3, 0, 6, 4, 1, 6, 7, 2, 0, 8, 7, 5, 8, 2, 9, 0, 8, 9, 0, 4, 4, 0, 2, 3, 7, 3, 2, 8, 9, 6, 0, 6, 7, 1, 7, 8, 1, 7, 9, 5, 3, 8, 7, 8, 4, 9, 4, 5, 1, 1, 6, 2, 2, 2, 6, 0, 5, 1, 3, 0, 6, 2, 7, 6, 1, 7, 5, 4, 9, 1, 8, 0, 3, 0, 0, 7, 1, 7, 3, 8, 6, 3, 4, 7, 8, 9, 3, 2, 2, 2, 7, 0, 5, 4, 1, 8, 4, 4, 7, 8, 9, 3, 2, 2, 1, 6, 5, 0, 3, 1, 5, 2, 7, 5, 7, 4, 2, 8, 7, 4, 3, 0, 5, 4, 4, 9, 8, 0, 1, 9, 7, 3, 4, 2, 2, 2, 0, 0, 1, 7, 0, 6, 6, 2, 4, 6, 0, 7, 9, 0, 3, 8, 1, 5, 4, 8, 8, 5, 9, 8, 4, 4, 2, 8, 5, 6, 0, 3, 8, 0, 0, 1, 0, 8, 6, 2, 5, 3, 3, 3, 4, 2, 8, 9, 0, 4, 6, 0, 5, 7, 8, 5, 1, 0, 0, 9, 6, 9, 4, 2, 5, 0, 7, 5, 3, 6, 5, 1, 4, 4, 8, 8, 4, 7, 4, 2, 9, 7, 7, 2, 3, 7, 9, 9, 2, 9, 9, 3, 9, 9, 7, 2, 9, 2, 2, 2, 2, 6, 8, 1, 9, 5, 7, 6, 6, 0, 1, 4, 4, 8, 4, 2, 3, 4, 2, 8, 7, 4, 7, 9, 3, 7, 1, 6, 2, 1, 3, 6, 4, 4, 5, 0, 0, 0, 3, 2, 5, 4, 2, 7, 0, 2, 9, 1, 1, 6, 1, 4, 4, 6, 9, 3, 9, 1, 0, 4, 9, 8, 9, 5, 0, 8, 6, 7, 4, 7, 7, 6, 2, 7, 6, 2, 3, 9, 5, 3, 2, 8, 9, 6, 0, 1, 7, 1, 1, 1, 9, 7, 3, 9, 1, 7, 3, 2, 8, 2, 1, 7, 6, 5, 1, 4, 1, 9, 6, 3, 0, 0, 4, 7, 6, 7, 7, 5, 5, 7, 4, 3, 5, 7, 6, 6, 2, 1, 2, 1, 1, 4, 0, 0, 9, 1, 5, 8, 8, 4, 2, 4, 7, 0, 1, 9, 4, 7, 1, 2, 7, 2, 1, 2, 7, 7, 1, 8, 0, 8, 5, 8, 9, 9, 8, 1, 7, 6, 7, 7, 8, 3, 7, 8, 4, 5, 5, 5, 1, 3, 5, 4, 8, 8, 5, 0, 8, 5, 4, 5, 8, 0, 5, 8, 5, 8, 7, 9, 4, 3, 6, 0, 9, 9, 8, 4, 3, 0, 3, 5, 9, 5, 2, 1, 7, 3, 3, 4, 2, 6, 5, 7, 0, 4, 1, 5, 6, 7, 1, 1, 3, 8, 5, 2, 3, 4, 3, 1, 6, 7, 4, 0, 8, 8, 4, 0, 2, 9, 3, 1, 8, 7, 3, 4, 9, 8, 5, 7, 2, 5, 2, 6, 8, 2, 6, 1, 9, 7, 2, 9, 4, 9, 6, 2, 6, 7, 8, 7, 4, 3, 4, 1, 3, 0, 8, 2, 8, 4, 0, 3, 4, 8, 5, 6, 2, 2, 0, 6, 8, 5, 5, 5, 5, 4, 2, 0, 6, 9, 8, 7, 4, 4, 4, 6, 3, 4, 6, 1, 0, 2, 2, 9, 0, 9, 1, 9, 3, 9, 9, 5, 6, 0, 4, 8, 6, 8, 0, 4, 8, 4, 4, 0, 2, 8, 8, 8, 2, 2, 9, 4, 7, 3, 2, 9, 0, 1, 7, 8, 2, 7, 2, 0, 0, 0, 2, 8, 8, 9, 2, 5, 7, 5, 3, 4, 0, 1, 4, 6, 4, 5, 4, 0, 6, 0, 9, 1, 2, 4, 2, 2, 2, 2, 7, 4, 2, 3, 8, 7, 9, 5, 2, 3, 8, 9, 6, 7, 1, 6, 5, 5, 1, 2, 5, 3, 3, 9, 3, 3, 2, 4, 2, 9, 7, 7, 0, 1, 8, 7, 8, 4, 4, 8, 6, 3, 7, 2, 3, 2, 6, 4, 3, 8, 2, 1, 4, 1, 1, 4, 5, 8, 5, 9, 1, 4, 4, 5, 0, 9, 1, 0, 6, 2, 2, 5, 6, 0, 5, 0, 6, 5, 6, 1, 0, 4, 5, 4, 3, 2, 4, 7, 3, 4, 3, 9, 6, 6, 3, 7, 3, 4, 3, 1, 7, 0, 5, 8, 2, 1, 7, 5, 9, 9, 6, 5, 9, 1, 8, 2, 4, 0, 3, 8, 8, 6, 1, 2, 7, 4, 9, 0, 8, 0, 1, 3, 9, 1, 0, 6, 0, 2, 5, 3, 9, 7, 9, 9, 5, 6, 7, 4, 3, 1, 8, 3, 7, 0, 7, 5, 3, 9, 8, 4, 7, 5, 6, 4, 8, 3, 0, 7, 0, 8, 0, 4, 3, 9, 4, 8, 4, 6, 7, 3, 5, 8, 2, 2, 5, 0, 6, 0, 2, 1, 6, 3, 5, 9, 9, 0, 1, 7, 3, 1, 9, 3, 3, 4, 3, 7, 5, 5, 2, 4, 3, 4, 1, 8, 9, 5, 2, 0, 9, 2, 4, 4, 8, 5, 2, 7, 5, 1, 9, 9, 3, 2, 5, 0, 3, 1, 7, 4, 0, 2, 8, 1, 5, 4, 9, 8, 7, 5, 8, 9, 0, 4, 8, 9, 7, 0, 7, 1, 4, 2, 6, 2, 1, 1, 6, 2, 0, 8, 3, 7, 3, 9, 2, 0, 0, 8, 2, 7, 9, 8, 1, 2, 1, 2, 6, 7, 4, 6, 2, 0, 2, 9, 7, 9, 8, 6, 5, 8, 3, 2, 7, 9, 4, 5, 9, 5, 2, 4, 2, 2, 4, 8, 5, 5, 9, 8, 1, 8, 0, 5, 5, 3, 6, 1, 1, 5, 1, 6, 0, 5, 5, 2, 8, 7, 8, 8, 3, 4, 1, 0, 5, 0, 3, 0, 3, 5, 1, 4, 2, 9, 6, 4, 4, 2, 0, 5, 0, 2, 4, 5, 4, 0, 5, 5, 2, 9, 4, 6, 4, 3, 4, 2, 9, 9, 4, 4, 1, 4, 5, 3, 8, 0, 1, 9, 1, 1, 5, 2, 5, 3, 9, 2, 6, 2, 8, 8, 5, 9, 4, 3, 7, 2, 7, 8, 9, 8, 3, 8, 0, 9, 8, 6, 8, 0, 1, 8, 5, 6, 4, 6, 8, 2, 7, 8, 1, 3, 5, 5, 7, 1, 7, 3, 9, 6, 6, 9, 3, 8, 3, 3, 2, 8, 6, 4, 4, 7, 5, 7, 3, 4, 5, 8, 4, 6, 5, 6, 3, 0, 8, 8, 7, 3, 7, 8, 2, 4, 0, 1, 3, 5, 6, 9, 6, 6, 2, 7, 6, 7, 1, 2, 9, 1, 4, 0, 8, 8, 4, 7, 9, 7, 8, 3, 5, 0, 7, 1, 4, 3, 1, 4, 4, 8, 3, 5, 0, 9, 9, 3, 5, 5, 7, 0, 2, 2, 1, 0, 0, 4, 7, 4, 3, 5, 6, 6, 1, 3, 3, 0, 5, 2, 3, 0, 1, 0, 2, 5, 2, 0, 7, 1, 6, 6, 2, 7, 6, 4, 7, 8, 3, 2, 1, 6, 9, 4, 0, 2, 2, 5, 3, 9, 4, 5, 0, 5, 7, 8, 9, 0, 9, 4, 7, 3, 4, 9, 4, 0, 0, 4, 6, 1, 5, 1, 6, 8, 6, 0, 2, 6, 2, 8, 1, 8, 2, 4, 9, 2, 1, 1, 0, 0, 2, 1, 1, 1, 2, 7, 6, 5, 4, 9, 4, 2, 5, 6, 2, 1, 2, 4, 3, 3, 7, 5, 3, 1, 9, 7, 4, 3, 3, 7, 0, 5, 9, 8, 7, 7, 0, 8, 4, 9, 4, 1, 0, 1, 0, 7, 3, 5, 4, 1, 6, 4, 7, 1, 9, 8, 2, 0, 2, 9, 3, 5, 1, 3, 7, 0, 2, 7, 4, 2, 1, 0, 0, 1, 8, 5, 4, 2, 1, 2, 2, 2, 3, 3, 6, 6, 7, 6, 7, 0, 8, 9, 9, 7, 9, 6, 5, 4, 1, 4, 9, 2, 8, 4, 1, 2, 5, 8, 3, 7, 7, 8, 0, 2, 8, 9, 9, 5, 3, 9, 9, 0, 9, 4, 8, 7, 0, 0, 6, 2, 3, 7, 6, 9, 7, 9, 2, 2, 3, 8, 4, 5, 7, 0, 1, 9, 1, 1, 8, 8, 3, 4, 6, 0, 9, 4, 1, 7, 6, 7, 0, 7, 9, 1, 7, 1, 9, 0, 7, 5, 7, 7, 1, 8, 6, 0, 5, 7, 0, 8, 5, 3, 1, 6, 6, 4, 8, 1, 7, 4, 7, 8, 0, 2, 2, 4, 7, 1, 0, 4, 4, 8, 4, 6, 5, 2, 2, 2, 4, 1, 7, 7, 2, 3, 2, 0, 3, 1, 9, 1, 7, 1, 1, 1, 0, 2, 2, 0, 2, 3, 5, 1, 0, 7, 6, 6, 8, 3, 7, 2, 2, 4, 3, 6, 2, 6, 0, 7, 5, 0, 0, 4, 5, 3, 7, 8, 4, 4, 9, 1, 4, 7, 3, 2, 8, 8, 3, 8, 2, 3, 9, 1, 7, 1, 8, 9, 6, 2, 6, 4, 2, 7, 6, 3, 1, 2, 9, 7, 2, 1, 5, 2, 4, 7, 9, 1, 2, 2, 8, 0, 8, 6, 0, 4, 9, 2, 2, 0, 7, 9, 9, 9, 1, 1, 5, 1, 6, 3, 8, 9, 7, 5, 5, 7, 1, 2, 0, 7, 8, 1, 4, 9, 1, 5, 9, 0, 4, 3, 5, 5, 8, 3, 6, 7, 0, 2, 1, 0, 2, 3, 4, 3, 1, 2, 5, 9, 0, 8, 5, 9, 9, 4, 2, 6, 8, 5, 7, 1, 0, 4, 7, 8, 0, 6, 5, 5, 4, 6, 7, 2, 1, 3, 6, 0, 8, 9, 0, 4, 7, 6, 5, 1, 0, 2, 0, 0, 4, 1, 7, 0, 1, 2, 9, 5, 8, 2, 5, 2, 7, 0, 1, 7, 4, 6, 9, 2, 7, 0, 7, 2, 3, 4, 3, 4, 1, 7, 5, 8, 2, 4, 6, 6, 0, 2, 7, 8, 1, 0, 0, 4, 2, 3, 3, 2, 4, 8, 6, 2, 3, 1, 9, 0, 8, 3, 1, 2, 0, 5, 0, 0, 9, 9, 5, 5, 2, 5, 4, 2, 9, 9, 9, 6, 3, 3, 0, 0, 9, 8, 5, 9, 6, 7, 2, 2, 8, 6, 3, 3, 6, 5, 9, 5, 3, 7, 6, 0, 7, 8, 5, 7, 8, 0, 4, 0, 2, 9, 7, 4, 3, 1, 8, 6, 8, 2, 1, 5, 4, 0, 2, 0, 7, 1, 8, 5, 2, 1, 6, 4, 9, 2, 3, 5, 0, 4, 4, 8, 3, 9, 4, 3, 5, 8, 9, 7, 0, 3, 3, 5, 4, 4, 6, 8, 5, 8, 6, 5, 2, 3, 3, 2, 8, 3, 1, 6, 4, 0, 2, 9, 3, 5, 9, 5, 5, 4, 8, 3, 3, 1, 2, 1, 4, 1, 6, 0, 5, 6, 4, 2, 7, 2, 7, 6, 0, 3, 0, 1, 7, 1, 4, 7, 2, 8, 6, 5, 7, 9, 4, 3, 8, 0, 1, 2, 5, 8, 1, 9, 5, 3, 6, 8, 0, 7, 6, 8, 5, 3, 7, 2, 7, 0, 2, 2, 3, 1, 5, 4, 1, 3, 0, 4, 0, 1, 0, 1, 7, 5, 4, 0, 2, 8, 2, 4, 8, 4, 0, 9, 8, 1, 0, 1, 3, 3, 9, 4, 1, 4, 9, 1, 6, 9, 0, 2, 2, 4, 6, 1, 2, 8, 5, 4, 4, 4, 5, 2, 5, 7, 7, 0, 2, 9, 4, 0, 7, 1, 6, 8, 5, 9, 1, 1, 4, 3, 1, 0, 4, 2, 1, 9, 4, 4, 4, 6, 7, 3, 1, 2, 5, 2, 7, 2, 3, 1, 7, 1, 3, 4, 1, 2, 9, 3, 2, 5, 7, 8, 7, 5, 6, 2, 9, 4, 6, 7, 9, 3, 0, 5, 7, 2, 9, 2, 1, 3, 8, 3, 7, 7, 2, 0, 5, 0, 3, 3, 9, 9, 2, 1, 9, 8, 8, 0, 3, 0, 5, 9, 4, 6, 4, 8, 0, 8, 0, 9, 8, 7, 2, 1, 8, 1, 6, 4, 5, 7, 5, 7, 5, 8, 5, 0, 4, 2, 7, 1, 7, 4, 9, 8, 2, 8, 5, 1, 3, 7, 0, 2, 3, 3, 4, 2, 2, 3, 8, 4, 8, 9, 8, 8, 5, 0, 1, 2, 6, 0, 6, 7, 8, 2, 1, 5, 7, 0, 4, 2, 5, 1, 2, 0, 2, 2, 7, 2, 0, 0, 4, 8, 0, 9, 3, 6, 0, 2, 5, 0, 8, 8, 7, 5, 1, 6, 3, 2, 3, 9, 6, 1, 0, 2, 1, 8, 2, 6, 7, 0, 9, 5, 5, 7, 8, 7, 6, 3, 8, 8, 4, 0, 3, 0, 0, 9, 6, 1, 6, 9, 9, 4, 4, 6, 0, 5, 8, 6, 0, 3, 0, 8, 4, 1, 6, 2, 4, 1, 2, 0, 0, 1, 8, 2, 2, 2, 2, 9, 1, 2, 7, 8, 4, 5, 4, 9, 5, 6, 3, 6, 0, 0, 1, 8, 7, 4, 0, 6, 3, 8, 5, 1, 4, 2, 5, 8, 2, 2, 5, 5, 0, 4, 6, 2, 2, 1, 9, 5, 0, 2, 6, 5, 8, 4, 2, 7, 4, 2, 4, 9, 8, 7, 8, 9, 7, 9, 4, 2, 3, 1, 4, 1, 2, 9, 6, 3, 8, 0, 2, 0, 1, 0, 9, 2, 4, 3, 4, 2, 2, 1, 4, 6, 4, 9, 8, 4, 8, 7, 4, 3, 7, 7, 1, 8, 0, 3, 9, 3, 8, 3, 6, 0, 7, 7, 0, 8, 9, 5, 4, 4, 6, 2, 3, 3, 5, 5, 3, 7, 0, 9, 4, 0, 8, 1, 5, 9, 2, 9, 8, 0, 3, 4, 1, 8, 5, 5, 0, 0, 8, 0, 7, 3, 8, 9, 2, 6, 2, 7, 8, 8, 4, 3, 2, 7, 3, 9, 3, 0, 8, 6, 4, 8, 5, 6, 2, 3, 0, 8, 7, 4, 0, 6, 8, 4, 9, 0, 6, 1, 4, 3, 3, 2, 0, 0, 0, 5, 2, 4, 7, 6, 9, 5, 8, 5, 2, 0, 8, 5, 0, 0, 7, 4, 3, 7, 6, 1, 2, 0, 1, 2, 9, 7, 8, 6, 4, 5, 3, 0, 7, 9, 3, 8, 1, 9, 6, 0, 0, 6, 2, 9, 2, 3, 0, 1, 2, 3, 8, 4, 1, 5, 2, 4, 1, 6, 2, 3, 3, 2, 9, 5, 1, 8, 8, 6, 8, 6, 8, 1, 6, 8, 4, 4, 1, 1, 9, 4, 7, 1, 4, 6, 8, 2, 6, 3, 7, 5, 3, 7, 8, 4, 6, 7, 7, 9, 9, 6, 5, 1, 8, 7, 5, 9, 2, 4, 4, 8, 0, 8, 6, 5, 9, 0, 7, 9, 1, 1, 1, 4, 2, 8, 6, 3, 4, 3, 0, 4, 2, 9, 9, 2, 2, 7, 4, 6, 6, 1, 6, 5, 4, 0, 6, 1, 2, 3, 8, 7, 9, 0, 9, 2, 9, 8, 0, 2, 7, 0, 5, 2, 0, 2, 7, 9, 8, 7, 0, 7, 8, 5, 5, 6, 0, 1, 2, 3, 1, 6, 0, 3, 2, 5, 6, 3, 7, 0, 7, 6, 6, 9, 7, 0, 3, 2, 5, 2, 9, 8, 9, 6, 0, 0, 1, 8, 1, 7, 6, 2, 6, 4, 0, 7, 7, 5, 1, 8, 3, 9, 2, 5, 5, 0, 0, 6, 9, 2, 7, 6, 2, 0, 6, 9, 5, 7, 5, 7, 6, 0, 6, 2, 6, 4, 9, 3, 5, 9, 2, 0, 6, 7, 1, 5, 0, 2, 1, 9, 2, 8, 1, 0, 2, 4, 3, 7, 3, 2, 6, 1, 6, 7, 2, 4, 9, 4, 8, 2, 1, 1, 8, 6, 6, 2, 5, 0, 6, 3, 4, 2, 4, 9, 9, 8, 6, 0, 2, 2, 8, 6, 2, 2, 1, 9, 0, 8, 7, 2, 9, 8, 1, 0, 2, 2, 3, 7, 4, 1, 9, 1, 6, 2, 1, 6, 1, 6, 2, 8, 6, 7, 1, 0, 7, 8, 5, 1, 1, 1, 6, 5, 2, 5, 9, 9, 3, 4, 2, 2, 1, 1, 4, 7, 5, 9, 4, 8, 0, 7, 4, 9, 0, 5, 2, 0, 7, 3, 6, 1, 1, 7, 3, 1, 0, 3, 2, 1, 8, 7, 5, 4, 9, 3, 6, 0, 6, 8, 2, 6, 2, 5, 3, 5, 9, 0, 8, 2, 4, 9, 8, 7, 6, 3, 7, 6, 9, 0, 3, 4, 4, 0, 7, 0, 7, 3, 0, 4, 5, 7, 4, 7, 1, 7, 1, 3, 8, 2, 4, 7, 1, 1, 2, 7, 6, 1, 4, 3, 7, 3, 6, 8, 0, 2, 9, 1, 9, 2, 7, 5, 9, 1, 2, 6, 7, 4, 5, 4, 2, 2, 5, 6, 5, 8, 2, 4, 5, 2, 0, 4, 2, 7, 4, 4, 4, 0, 0, 1, 7, 0, 5, 9, 5, 5, 5, 5, 9, 5, 3, 6, 0, 1, 2, 2, 5, 1, 0, 9, 5, 3, 4, 6, 7, 5, 0, 5, 5, 0, 3, 3, 0, 2, 9, 7, 4, 4, 0, 5, 2, 9, 3, 9, 1, 7, 3, 6, 2, 3, 0, 9, 5, 0, 4, 0, 6, 7, 4, 5, 3, 5, 2, 8, 3, 2, 0, 7, 9, 2, 8, 3, 8, 3, 1, 0, 3, 0, 6, 8, 3, 0, 4, 0, 9, 5, 8, 7, 5, 8, 5, 5, 9, 7, 6, 2, 5, 8, 9, 8, 5, 7, 3, 9, 8, 9, 4, 6, 0, 7, 9, 1, 3, 9, 6, 5, 2, 9, 0, 6, 5, 0, 2, 1, 6, 9, 2, 8, 2, 7, 3, 5, 2, 1, 6, 7, 6, 4, 4, 0, 3, 0, 4, 6, 0, 3, 1, 3, 6, 3, 2, 5, 3, 4, 5, 7, 3, 8, 4, 5, 3, 1, 2, 4, 4, 6, 7, 4, 9, 2, 6, 2, 9, 7, 0, 6, 4, 3, 7, 6, 8, 7, 2, 3, 5, 4, 5, 5, 4, 8, 7, 9, 3, 9, 3, 8, 4, 7, 2, 6, 9, 2, 6, 2, 4, 0, 4, 8, 3, 2, 9, 8, 8, 9, 3, 5, 7, 7, 2, 2, 0, 1, 3, 7, 4, 0, 1, 6, 4, 1, 1, 7, 3, 9, 3, 6, 3, 9, 0, 0, 6, 6, 9, 2, 0, 3, 9, 6, 9, 2, 2, 4, 8, 6, 1, 9, 4, 4, 5, 2, 9, 6, 3, 8, 0, 1, 9, 2, 7, 9, 5, 7, 7, 0, 9, 6, 2, 5, 6, 8, 7, 8, 4, 0, 0, 0, 5, 2, 9, 9, 6, 8, 1, 1, 0, 6, 8, 8, 7, 9, 6, 1, 5, 2, 2, 8, 7, 6, 9, 0, 4, 5, 8, 9, 9, 4, 4, 5, 2, 9, 6, 2, 0, 7, 6, 6, 7, 8, 1, 8, 5, 1, 1, 4, 9, 5, 7, 9, 7, 8, 2, 9, 1, 0, 9, 9, 2, 7, 5, 2, 7, 0, 5, 2, 4, 4, 0, 3, 0, 3, 9, 0, 4, 5, 5, 7, 2, 4, 4, 3, 3, 5, 8, 4, 5, 4, 6, 4, 0, 6, 5, 1, 9, 8, 3, 3, 1, 8, 4, 8, 4, 5, 9, 0, 8, 9, 8, 5, 4, 9, 5, 4, 9, 9, 9, 0, 5, 1, 0, 3, 8, 1, 9, 9, 8, 9, 9, 9, 0, 4, 3, 9, 8, 0, 4, 5, 7, 8, 5, 7, 8, 0, 6, 2, 8, 6, 6, 1, 3, 8, 8, 8, 1, 9, 5, 3, 7, 2, 1, 0, 4, 0, 7, 4, 4, 2, 6, 4, 6, 2, 5, 9, 2, 0, 3, 1, 8, 5, 9, 5, 3, 5, 7, 3, 3, 1, 7, 3, 5, 2, 1, 9, 9, 5, 2, 4, 1, 2, 8, 8, 1, 5, 7, 6, 9, 3, 3, 8, 2, 7, 6, 3, 2, 5, 2, 6, 0, 4, 3, 2, 2, 7, 0, 8, 1, 0, 4, 0, 6, 1, 8, 7, 9, 2, 5, 4, 2, 8, 7, 8, 6, 6, 8, 1, 7, 8, 7, 2, 7, 4, 7, 8, 3, 7, 6, 3, 8, 7, 3, 5, 0, 2, 3, 8, 0, 4, 0, 2, 8, 0, 9, 9, 2, 6, 7, 7, 4, 8, 6, 3, 4, 2, 0, 0, 2, 9, 1, 7, 1, 5, 9, 3, 2, 8, 8, 2, 1, 2, 5, 0, 4, 3, 7, 2, 9, 5, 5, 1, 4, 7, 0, 9, 7, 0, 5, 3, 0, 4, 2, 7, 2, 5, 8, 9, 8, 8, 5, 5, 9, 9, 3, 1, 2, 1, 3, 8, 4, 8, 6, 0, 1, 4, 5, 0, 1, 8, 2, 4, 3, 1, 5, 7, 2, 8, 2, 1, 7, 5, 9, 1, 0, 5, 7, 3, 1, 9, 3, 0, 1, 2, 2, 7, 7, 9, 9, 9, 3, 8, 5, 0, 2, 2, 4, 9, 6, 6, 6, 1, 0, 3, 1, 4, 5, 5, 4, 7, 7, 5, 9, 6, 7, 1, 6, 5, 3, 2, 9, 7, 4, 6, 0, 1, 4, 8, 5, 6, 1, 8, 3, 7, 3, 9, 2, 2, 1, 5, 3, 9, 0, 7, 4, 4, 2, 5, 0, 6, 4, 7, 8, 1, 8, 1, 7, 8, 9, 7, 1, 0, 3, 6, 3, 7, 2, 1, 4, 5, 9, 8, 9, 7, 9, 3, 3, 0, 1, 8, 6, 7, 5, 5, 1, 0, 2, 8, 5, 2, 3, 0, 7, 8, 6, 2, 9, 5, 5, 7, 9, 1, 8, 1, 9, 1, 2, 0, 3, 0, 0, 3, 8, 7, 4, 0, 7, 5, 1, 7, 2, 0, 5, 5, 0, 5, 8, 5, 7, 7, 8, 8, 1, 8, 3, 3, 0, 8, 8, 1, 9, 0, 7, 5, 9, 9, 5, 7, 0, 0, 3, 1, 0, 9, 9, 0, 7, 9, 1, 6, 9, 1, 7, 7, 7, 4, 1, 1, 4, 4, 2, 9, 1, 7, 0, 2, 6, 4, 4, 2, 7, 4, 5, 5, 1, 9, 1, 4, 3, 1, 7, 3, 1, 2, 2, 7, 1, 3, 1, 4, 8, 3, 7, 7, 2, 9, 8, 5, 0, 0, 3, 1, 7, 1, 7, 8, 7, 3, 2, 4, 1, 5, 0, 6, 7, 7, 3, 9, 7, 9, 8, 2, 7, 8, 2, 3, 9, 5, 1, 8, 4, 6, 8, 5, 9, 1, 1, 4, 8, 3, 3, 3, 7, 8, 7, 9, 2, 4, 9, 3, 6, 8, 8, 0, 2, 4, 6, 6, 5, 8, 6, 9, 1, 4, 0, 7, 2, 1, 5, 2, 1, 6, 7, 0, 0, 5, 9, 2, 4, 8, 3, 5, 2, 6, 5, 9, 7, 8, 3, 4, 0, 0, 7, 9, 9, 5, 7, 0, 6, 5, 9, 0, 5, 8, 9, 1, 8, 4, 2, 2, 3, 7, 0, 5, 2, 0, 5, 8, 3, 9, 7, 2, 6, 6, 4, 5, 2, 4, 0, 2, 8, 0, 0, 8, 9, 5, 6, 7, 3, 6, 9, 0, 0, 2, 6, 0, 1, 0, 9, 2, 5, 4, 7, 6, 9, 2, 4, 1, 8, 7, 7, 8, 3, 6, 0, 8, 5, 9, 5, 1, 5, 2, 5, 8, 4, 2, 0, 6, 8, 1, 4, 5, 6, 8, 8, 0, 7, 6, 0, 0, 0, 2, 7, 1, 5, 7, 4, 9, 0, 8, 3, 2, 9, 6, 8, 2, 6, 5, 3, 4, 5, 9, 8, 6, 2, 6, 3, 7, 0, 8, 6, 7, 0, 8, 1, 9, 7, 1, 4, 6, 4, 3, 8, 4, 6, 4, 5, 8, 9, 4, 2, 8, 5, 4, 7, 3, 5, 5, 4, 7, 6, 8, 7, 6, 8, 0, 7, 8, 8, 1, 6, 7, 2, 4, 9, 7, 0, 0, 3, 5, 9, 1, 8, 2, 4, 7, 5, 7, 5, 3, 9, 9, 1, 9, 7, 0, 9, 0, 8, 4, 3, 7, 3, 6, 7, 8, 5, 5, 5, 9, 7, 9, 0, 2, 4, 1, 7, 4, 3, 8, 3, 6, 4, 0, 5, 5, 7, 6, 5, 7, 8, 7, 9, 6, 4, 5, 9, 5, 9, 9, 1, 0, 3, 5, 8, 3, 5, 1, 9, 4, 9, 1, 4, 7, 9, 9, 8, 9, 5, 6, 1, 2, 0, 2, 9, 9, 5, 9, 4, 1, 7, 3, 2, 7, 2, 0, 6, 0, 7, 4, 6, 5, 1, 2, 0, 4, 1, 2, 1, 2, 2, 1, 0, 6, 6, 3, 2, 8, 4, 1, 2, 0, 7, 0, 5, 2, 4, 5, 4, 9, 5, 0, 0, 5, 0, 4, 8, 3, 8, 4, 2, 2, 2, 8, 7, 7, 8, 5, 7, 9, 9, 8, 7, 2, 9, 5, 8, 6, 4, 6, 4, 7, 9, 0, 1, 1, 9, 3, 0, 2, 7, 2, 6, 6, 6, 6, 1, 0, 3, 4, 0, 1, 2, 9, 0, 1, 3, 6, 3, 8, 2, 6, 1, 3, 6, 4, 2, 3, 7, 1, 9, 1, 2, 1, 7, 5, 9, 0, 9, 9, 3, 6, 5, 1, 1, 0, 9, 5, 6, 7, 4, 9, 1, 4, 5, 1, 9, 6, 4, 8, 6, 0, 9, 1, 8, 5, 4, 4, 4, 9, 1, 7, 9, 6, 5, 0, 0, 0, 9, 2, 0, 2, 9, 1, 2, 1, 4, 5, 9, 0, 5, 5, 1, 0, 9, 9, 6, 0, 3, 8, 2, 9, 6, 4, 6, 9, 1, 2, 5, 8, 4, 3, 9, 1, 2, 7, 9, 8, 2, 4, 0, 5, 9, 1, 7, 2, 9, 4, 1, 4, 7, 2, 7, 9, 1, 3, 0, 4, 3, 5, 2, 7, 8, 9, 8, 8, 1, 6, 2, 8, 3, 2, 5, 1, 0, 6, 0, 6, 2, 5, 5, 0, 7, 4, 6, 7, 2, 5, 4, 9, 8, 8, 1, 3, 2, 5, 1, 3, 9, 1, 7, 4, 4, 7, 2, 4, 1, 2, 0, 2, 9, 3, 2, 4, 3, 5, 8, 8, 2, 0, 8, 2, 7, 7, 9, 7, 4, 5, 8, 6, 4, 8, 1, 8, 2, 5, 9, 6, 2, 4, 0, 6, 1, 4, 5, 9, 2, 9, 0, 8, 4, 2, 2, 1, 3, 7, 0, 2, 4, 4, 8, 0, 9, 9, 4, 8, 8, 4, 2, 0, 1, 9, 2, 2, 8, 7, 5, 6, 7, 5, 6, 6, 2, 6, 2, 7, 0, 9, 0, 8, 3, 5, 1, 4, 6, 4, 1, 4, 2, 4, 2, 1, 4, 9, 2, 8, 8, 0, 7, 9, 0, 8, 6, 4, 8, 5, 8, 7, 0, 8, 7, 6, 1, 1, 7, 0, 9, 1, 3, 9, 3, 4, 5, 1, 8, 5, 4, 5, 0, 4, 1, 8, 3, 2, 2, 0, 3, 6, 7, 1, 5, 9, 0, 9, 3, 3, 1, 8, 3, 8, 0, 8, 5, 4, 3, 1, 6, 8, 9, 1, 7, 2, 8, 9, 3, 2, 1, 3, 5, 5, 9, 2, 8, 4, 4, 2, 5, 3, 0, 4, 7, 9, 7, 5, 8, 8, 9, 3, 4, 2, 0, 1, 3, 4, 2, 3, 5, 8, 2, 5, 0, 2, 4, 4, 3, 9, 3, 6, 9, 5, 7, 3, 2, 6, 2, 1, 1, 5, 7, 2, 4, 0, 6, 7, 0, 0, 2, 7, 1, 2, 7, 5, 5, 5, 3, 6, 3, 1, 1, 4, 5, 5, 6, 7, 4, 2, 5, 7, 4, 8, 3, 3, 5, 7, 8, 6, 0, 6, 8, 5, 0, 4, 8, 3, 8, 4, 9, 6, 4, 4, 3, 5, 7, 2, 5, 9, 9, 4, 9, 2, 1, 1, 2, 2, 2, 0, 5, 7, 3, 5, 6, 9, 0, 0, 0, 3, 6, 8, 0, 8, 9, 0, 3, 9, 3, 6, 6, 5, 2, 8, 7, 8, 9, 7, 5, 2, 4, 6, 5, 3, 7, 2, 1, 0, 6, 9, 2, 9, 1, 4, 2, 0, 8, 0, 5, 0, 9, 1, 5, 6, 1, 2, 0, 8, 6, 8, 4, 1, 8, 0, 8, 4, 8, 4, 7, 6, 0, 7, 7, 5, 7, 1, 7, 7, 9, 7, 7, 5, 1, 6, 3, 8, 2, 1, 8, 2, 7, 9, 9, 5, 8, 1, 0, 5, 7, 7, 6, 7, 8, 0, 0, 3, 5, 9, 4, 8, 2, 7, 7, 4, 4, 5, 6, 5, 8, 3, 4, 2, 3, 4, 0, 3, 2, 0, 2, 6, 1, 5, 0, 6, 6, 1, 9, 9, 5, 1, 9, 2, 7, 0, 8, 3, 4, 5, 1, 1, 2, 1, 2, 9, 4, 2, 5, 4, 1, 5, 5, 1, 5, 3, 9, 4, 5, 3, 1, 3, 6, 1, 2, 4, 0, 4, 5, 9, 3, 6, 9, 6, 3, 5, 0, 3, 6, 0, 5, 8, 3, 3, 6, 7, 7, 9, 9, 4, 0, 2, 1, 2, 4, 8, 2, 0, 1, 2, 7, 4, 0, 9, 4, 2, 3, 3, 1, 1, 5, 1, 8, 4, 6, 1, 6, 7, 7, 9, 6, 8, 2, 3, 0, 0, 6, 9, 0, 1, 3, 9, 1, 4, 5, 8, 2, 8, 8, 1, 9, 0, 2, 0, 7, 2, 7, 8, 8, 8, 9, 1, 5, 1, 6, 8, 5, 1, 7, 4, 3, 4, 3, 0, 6, 2, 2, 6, 3, 8, 5, 0, 1, 0, 3, 7, 9, 1, 9, 2, 6, 5, 8, 1, 6, 7, 4, 9, 3, 1, 7, 8, 3, 2, 2, 5, 8, 7, 6, 4, 2, 2, 4, 3, 5, 0, 4, 5, 2, 6, 0, 0, 0, 9, 8, 1, 8, 8, 9, 0, 9, 1, 4, 0, 7, 8, 5, 9, 9, 0, 7, 3, 1, 8, 4, 3, 0, 9, 4, 2, 7, 6, 5, 5, 6, 2, 0, 2, 7, 7, 5, 8, 9, 9, 6, 5, 3, 2, 1, 9, 0, 8, 9, 3, 4, 8, 7, 6, 5, 0, 2, 1, 0, 4, 5, 8, 2, 4, 8, 6, 4, 8, 9, 0, 4, 5, 1, 3, 0, 2, 7, 8, 3, 1, 5, 3, 1, 1, 2, 3, 4, 1, 6, 2, 5, 9, 2, 8, 4, 0, 6, 9, 4, 0, 0, 5, 8, 5, 6, 8, 7, 4, 6, 8, 3, 1, 8, 4, 5, 2, 7, 3, 9, 9, 9, 2, 7, 8, 6, 7, 2, 6, 3, 6, 0, 3, 1, 1, 4, 1, 4, 0, 4, 0, 7, 2, 3, 8, 2, 7, 2, 8, 8, 9, 2, 3, 8, 7, 5, 1, 8, 9, 0, 2, 7, 2, 9, 1, 0, 5, 0, 1, 2, 5, 8, 9, 1, 9, 1, 2, 9, 5, 2, 2, 5, 8, 7, 6, 4, 7, 4, 8, 2, 4, 1, 7, 5, 2, 9, 6, 5, 6, 4, 9, 9, 6, 0, 4, 3, 9, 0, 4, 2, 2, 7, 9, 1, 6, 5, 4, 7, 0, 0, 2, 9, 6, 1, 4, 2, 3, 5, 9, 5, 5, 3, 2, 0, 0, 1, 6, 6, 7, 8, 6, 8, 5, 8, 3, 7, 8, 4, 0, 9, 4, 8, 0, 8, 7, 4, 3, 0, 3, 2, 7, 7, 5, 3, 8, 3, 9, 4, 7, 9, 3, 2, 9, 4, 4, 7, 8, 9, 3, 2, 2, 9, 4, 3, 7, 9, 3, 8, 9, 1, 1, 8, 6, 0, 1, 2, 8, 4, 9, 3, 4, 6, 3, 1, 0, 4, 6, 4, 6, 3, 7, 6, 6, 6, 1, 2, 7, 9, 5, 0, 9, 9, 1, 8, 7, 8, 1, 1, 0, 6, 7, 3, 1, 9, 0, 9, 2, 2, 1, 0, 4, 3, 6, 6, 7, 0, 5, 7, 4, 2, 0, 6, 2, 5, 6, 7, 7, 4, 6, 1, 3, 0, 0, 6, 2, 8, 5, 9, 7, 8, 5, 6, 4, 3, 1, 5, 5, 0, 3, 2, 7, 8, 0, 3, 9, 6, 8, 2, 1, 9, 7, 4, 0, 9, 1, 8, 4, 3, 2, 2, 1, 7, 5, 6, 7, 7, 5, 7, 1, 0, 4, 3, 9, 3, 3, 0, 2, 1, 9, 3, 0, 3, 3, 3, 4, 1, 0, 0, 2, 3, 3, 0, 9, 2, 9, 4, 8, 9, 4, 8, 2, 8, 0, 3, 9, 0, 1, 2, 0, 6, 1, 9, 6, 0, 7, 9, 9, 0, 4, 2, 7, 0, 1, 6, 5, 8, 9, 9, 0, 6, 5, 3, 4, 6, 1, 4, 4, 9, 3, 5, 7, 2, 8, 0, 0, 3, 2, 9, 7, 0, 8, 1, 4, 7, 3, 0, 1, 6, 9, 8, 4, 3, 5, 2, 5, 9, 8, 7, 5, 5, 9, 8, 9, 4, 6, 0, 4, 0, 0, 1, 7, 9, 8, 7, 8, 1, 8, 1, 0, 0, 1, 3, 3, 3, 6, 2, 4, 9, 2, 1, 3, 2, 6, 8, 5, 8, 2, 9, 6, 6, 0, 1, 0, 6, 0, 2, 8, 2, 6, 3, 0, 2, 4, 3, 9, 9, 4, 9, 6, 0, 8, 7, 7, 7, 7, 4, 9, 2, 8, 3, 2, 4, 2, 6, 4, 6, 7, 4, 1, 6, 8, 4, 4, 6, 2, 6, 8, 7, 9, 4, 9, 3, 3, 4, 0, 1, 1, 0, 4, 6, 4, 2, 4, 2, 6, 1, 2, 6, 3, 5, 0, 7, 2, 1, 3, 2, 0, 5, 8, 1, 5, 2, 8, 5, 0, 7, 4, 8, 9, 2, 6, 3, 5, 9, 8, 3, 9, 1, 1, 9, 4, 2, 5, 3, 4, 6, 2, 3, 6, 9, 4, 9, 1, 1, 3, 4, 3, 9, 4, 1, 5, 3, 7, 7, 7, 9, 3, 8, 7, 9, 8, 6, 1, 8, 1, 8, 6, 9, 3, 0, 5, 9, 3, 8, 3, 6, 6, 9, 9, 8, 6, 9, 4, 1, 5, 2, 2, 9, 4, 7, 1, 9, 8, 2, 9, 3, 0, 0, 8, 5, 7, 9, 7, 5, 4, 0, 4, 0, 8, 5, 8, 2, 8, 7, 2, 0, 1, 2, 7, 0, 4, 5, 5, 3, 0, 0, 2, 1, 4, 7, 6, 7, 4, 0, 6, 7, 2, 9, 8, 6, 2, 4, 0, 5, 0, 8, 3, 0, 0, 0, 7, 9, 6, 8, 0, 6, 4, 5, 2, 9, 9, 5, 0, 0, 8, 1, 1, 3, 3, 7, 8, 7, 7, 2, 4, 7, 8, 9, 2, 9, 9, 4, 9, 3, 0, 1, 0, 0, 6, 7, 5, 9, 3, 5, 3, 4, 6, 2, 4, 8, 8, 0, 0, 6, 2, 4, 4, 6, 9, 4, 7, 5, 1, 3, 5, 2, 7, 7, 1, 1, 6, 6, 1, 7, 9, 3, 1, 9, 7, 1, 0, 9, 0, 6, 9, 2, 7, 7, 8, 7, 0, 8, 1, 7, 7, 7, 6, 8, 1, 5, 9, 5, 9, 1, 4, 1, 0, 7, 8, 4, 7, 8, 0, 8, 3, 7, 6, 6, 2, 6, 7, 0, 5, 0, 8, 3, 7, 4, 1, 8, 0, 9, 8, 0, 8, 0, 1, 5, 0, 2, 8, 0, 8, 4, 7, 3, 2, 5, 9, 4, 4, 2, 1, 9, 7, 3, 0, 9, 5, 6, 8, 4, 7, 8, 9, 8, 1, 9, 3, 7, 0, 2, 4, 2, 5, 6, 4, 2, 4, 3, 9, 7, 7, 9, 9, 2, 2, 1, 7, 5, 6, 8, 5, 4, 9, 4, 9, 2, 3, 7, 3, 6, 3, 4, 8, 8, 5, 2, 4, 3, 7, 6, 7, 1, 1, 9, 7, 0, 0, 4, 9, 0, 2, 6, 8, 6, 1, 1, 4, 0, 5, 2, 0, 7, 7, 4, 5, 0, 4, 1, 8, 5, 9, 0, 5, 3, 0, 0, 2, 4, 5, 4, 4, 4, 2, 1, 9, 7, 4, 6, 7, 9, 6, 5, 1, 0, 9, 9, 7, 7, 7, 4, 2, 4, 6, 3, 9, 1, 8, 3, 7, 9, 6, 8, 6, 9, 1, 2, 9, 5, 0, 0, 0, 5, 7, 9, 2, 3, 7, 7, 4, 6, 8, 6, 0, 8, 1, 8, 4, 2, 9, 1, 9, 3, 1, 5, 8, 8, 6, 9, 4, 7, 6, 6, 9, 9, 0, 1, 9, 4, 4, 7, 7, 5, 5, 0, 8, 5, 1, 1, 4, 8, 6, 6, 2, 0, 9, 9, 3, 1, 4, 1, 3, 2, 3, 5, 7, 1, 5, 2, 1, 8, 9, 0, 4, 1, 1, 9, 9, 5, 9, 6, 9, 8, 9, 0, 8, 5, 2, 6, 6, 3, 0, 1, 2, 0, 6, 3, 7, 7, 4, 6, 3, 5, 7, 3, 2, 5, 3, 5, 4, 3, 7, 9, 6, 5, 5, 2, 4, 3, 1, 6, 5, 4, 1, 6, 5, 7, 4, 8, 9, 4, 3, 0, 6, 8, 0, 6, 6, 6, 7, 4, 3, 3, 2, 2, 5, 5, 5, 6, 1, 5, 1, 1, 1, 3, 0, 5, 3, 8, 3, 4, 2, 4, 1, 2, 3, 5, 4, 6, 1, 2, 8, 9, 0, 3, 6, 1, 8, 8, 3, 0, 1, 9, 8, 2, 8, 7, 4, 4, 5, 0, 0, 0, 7, 3, 2, 7, 8, 9, 2, 0, 7, 7, 1, 0, 5, 1, 3, 5, 5, 7, 3, 7, 0, 2, 5, 4, 7, 0, 1, 5, 3, 8, 5, 4, 7, 7, 8, 9, 9, 5, 2, 2, 5, 8, 2, 7, 0, 0, 0, 2, 9, 3, 3, 9, 0, 8, 0, 0, 7, 1, 5, 9, 8, 7, 8, 0, 7, 1, 4, 2, 9, 9, 8, 4, 0, 2, 2, 6, 0, 8, 6, 4, 0, 0, 1, 6, 3, 8, 3, 3, 7, 2, 6, 2, 0, 8, 8, 8, 0, 6, 4, 4, 1, 5, 5, 9, 4, 4, 8, 6, 5, 2, 9, 1, 9, 3, 2, 9, 7, 6, 4, 5, 1, 5, 3, 7, 5, 3, 0, 1, 9, 6, 5, 2, 1, 4, 5, 7, 5, 7, 5, 7, 4, 6, 9, 9, 0, 1, 0, 1, 1, 1, 4, 4, 2, 3, 2, 9, 1, 1, 6, 4, 4, 1, 4, 8, 2, 6, 7, 5, 9, 5, 9, 9, 3, 0, 5, 8, 0, 0, 2, 4, 9, 1, 9, 8, 9, 3, 9, 2, 9, 6, 0, 7, 7, 2, 8, 4, 7, 8, 0, 4, 9, 0, 8, 8, 2, 4, 5, 5, 9, 0, 3, 5, 0, 2, 2, 6, 5, 0, 9, 9, 2, 9, 2, 5, 2, 0, 2, 6, 1, 2, 2, 5, 0, 1, 0, 3, 4, 9, 3, 6, 5, 5, 2, 5, 9, 4, 7, 2, 8, 8, 5, 3, 1, 3, 0, 9, 4, 8, 7, 1, 0, 0, 0, 5, 6, 3, 2, 1, 5, 7, 7, 5, 3, 1, 8, 8, 5, 9, 6, 0, 6, 7, 4, 3, 6, 6, 3, 8, 3, 3, 0, 4, 9, 6, 4, 3, 5, 2, 8, 1, 2, 9, 8, 4, 1, 1, 9, 8, 2, 8, 5, 5, 3, 4, 7, 3, 7, 1, 2, 4, 2, 0, 8, 4, 5, 4, 3, 1, 9, 4, 8, 2, 8, 0, 1, 8, 7, 6, 6, 2, 4, 1, 3, 6, 0, 5, 0, 1, 0, 0, 5, 8, 0, 1, 4, 2, 8, 0, 5, 6, 6, 2, 5, 5, 2, 2, 0, 5, 3, 1, 3, 8, 8, 1, 2, 6, 2, 7, 6, 8, 1, 1, 8, 8, 3, 5, 6, 5, 3, 7, 2, 4, 2, 6, 7, 5, 9, 1, 0, 5, 6, 3, 9, 3, 8, 9, 2, 5, 7, 1, 0, 3, 6, 9, 5, 1, 0, 1, 0, 5, 2, 7, 1, 1, 7, 0, 9, 1, 2, 1, 5, 7, 2, 1, 7, 0, 3, 5, 5, 4, 7, 7, 1, 0, 9, 4, 3, 4, 7, 2, 1, 7, 7, 7, 9, 3, 2, 6, 0, 7, 0, 4, 3, 2, 1, 4, 0, 6, 7, 9, 5, 8, 6, 5, 7, 9, 4, 5, 4, 9, 3, 0, 6, 3, 3, 2, 1, 4, 2, 2, 5, 4, 8, 8, 8, 8, 7, 6, 5, 1, 6, 7, 6, 3, 5, 7, 8, 7, 2, 4, 3, 1, 9, 1, 3, 0, 7, 7, 4, 5, 9, 2, 2, 4, 7, 1, 6, 1, 5, 4, 3, 6, 2, 5, 6, 7, 0, 2, 0, 3, 9, 2, 6, 5, 5, 7, 7, 1, 9, 9, 8, 8, 8, 6, 2, 2, 0, 0, 0, 4, 7, 7, 5, 2, 5, 8, 1, 0, 0, 8, 7, 5, 8, 0, 2, 1, 5, 1, 2, 1, 5, 9, 1, 7, 8, 7, 4, 7, 0, 3, 2, 8, 9, 2, 0, 7, 1, 8, 0, 2, 6, 3, 9, 9, 1, 2, 7, 1, 5, 9, 7, 4, 3, 9, 3, 9, 7, 8, 6, 8, 5, 8, 1, 3, 3, 7, 2, 6, 2, 1, 1, 4, 8, 2, 8, 2, 7, 2, 0, 3, 3, 2, 8, 6, 8, 4, 7, 4, 5, 4, 6, 6, 4, 7, 7, 4, 6, 7, 9, 0, 3, 0, 8, 7, 7, 0, 2, 7, 8, 3, 2, 4, 2, 2, 9, 1, 7, 1, 1, 8, 4, 3, 0, 4, 4, 6, 1, 9, 2, 0, 2, 7, 9, 4, 3, 3, 3, 4, 7, 9, 8, 0, 4, 2, 4, 3, 4, 7, 3, 0, 6, 7, 9, 9, 0, 2, 8, 6, 4, 2, 4, 3, 8, 2, 8, 0, 0, 2, 6, 6, 4, 1, 9, 2, 3, 1, 7, 9, 9, 1, 4, 2, 1, 9, 1, 0, 3, 8, 5, 5, 1, 6, 5, 6, 0, 2, 9, 2, 7, 2, 7, 4, 1, 0, 5, 9, 2, 4, 7, 5, 6, 6, 0, 8, 9, 9, 4, 2, 0, 2, 8, 3, 4, 1, 9, 5, 1, 0, 2, 6, 2, 2, 8, 7, 9, 8, 3, 8, 5, 1, 1, 1, 9, 1, 5, 1, 0, 2, 4, 8, 3, 0, 0, 5, 7, 7, 1, 2, 1, 2, 8, 0, 0, 4, 0, 5, 2, 1, 3, 5, 0, 3, 2, 4, 9, 0, 4, 0, 0, 5, 9, 7, 9, 8, 9, 6, 4, 7, 8, 0, 7, 0, 9, 4, 7, 6, 8, 0, 6, 0, 5, 7, 4, 7, 4, 1, 0, 2, 6, 2, 1, 1, 4, 5, 3, 7, 7, 0, 8, 1, 6, 9, 5, 7, 6, 7, 9, 6, 5, 6, 9, 8, 1, 0, 1, 9, 7, 9, 9, 4, 5, 2, 2, 5, 6, 3, 7, 4, 6, 2, 8, 5, 0, 1, 0, 9, 9, 7, 7, 3, 1, 6, 0, 3, 6, 6, 7, 4, 9, 3, 8, 4, 2, 2, 6, 5, 0, 0, 4, 3, 7, 2, 7, 2, 8, 9, 4, 8, 4, 6, 3, 0, 1, 9, 2, 4, 7, 9, 9, 4, 7, 7, 4, 1, 2, 2, 3, 7, 5, 2, 8, 1, 4, 6, 3, 8, 9, 2, 6, 1, 7, 7, 3, 1, 9, 4, 7, 0, 0, 0, 1, 7, 5, 3, 1, 3, 1, 8, 2, 9, 2, 8, 3, 0, 1, 9, 4, 6, 5, 3, 8, 4, 5, 8, 2, 6, 2, 5, 3, 5, 7, 6, 3, 2, 3, 6, 1, 3, 0, 2, 9, 3, 5, 4, 7, 6, 1, 8, 9, 5, 8, 8, 2, 2, 2, 0, 2, 1, 8, 2, 3, 9, 2, 8, 1, 6, 5, 5, 6, 9, 9, 1, 2, 6, 7, 9, 5, 2, 6, 3, 2, 4, 2, 7, 1, 2, 2, 1, 7, 9, 1, 5, 5, 2, 0, 9, 0, 0, 1, 0, 9, 0, 1, 7, 9, 1, 5, 4, 3, 8, 4, 8, 1, 8, 6, 8, 1, 0, 1, 7, 3, 8, 4, 4, 2, 3, 7, 3, 5, 7, 3, 2, 3, 0, 0, 2, 7, 8, 0, 1, 8, 2, 9, 8, 1, 1, 7, 2, 7, 9, 6, 1, 1, 4, 5, 9, 2, 9, 4, 1, 2, 1, 8, 1, 7, 0, 0, 0, 5, 1, 0, 9, 2, 4, 3, 3, 6, 4, 0, 2, 6, 9, 3, 0, 3, 0, 4, 6, 0, 2, 1, 1, 2, 2, 4, 9, 7, 9, 0, 1, 2, 0, 8, 2, 1, 3, 2, 9, 2, 7, 8, 8, 1, 7, 4, 7, 1, 8, 5, 7, 3, 5, 9, 5, 3, 2, 0, 3, 9, 5, 3, 0, 9, 5, 8, 5, 0, 8, 7, 4, 3, 9, 0, 3, 3, 9, 2, 5, 2, 9, 0, 9, 5, 1, 5, 4, 4, 8, 7, 9, 1, 5, 6, 3, 7, 2, 5, 1, 1, 4, 1, 5, 7, 4, 4, 1, 1, 9, 9, 8, 6, 5, 4, 6, 0, 4, 8, 9, 5, 7, 8, 9, 7, 8, 6, 9, 3, 6, 6, 6, 8, 2, 8, 0, 4, 8, 1, 4, 0, 6, 9, 1, 8, 7, 4, 9, 9, 6, 8, 3, 3, 4, 2, 2, 4, 4, 3, 0, 9, 3, 3, 5, 4, 1, 8, 7, 3, 8, 7, 4, 9, 8, 4, 8, 3, 8, 7, 2, 3, 1, 2, 8, 2, 0, 7, 4, 0, 0, 2, 1, 4, 5, 5, 9, 1, 3, 1, 9, 1, 3, 8, 7, 6, 9, 7, 9, 8, 9, 2, 0, 1, 7, 0, 0, 7, 7, 2, 8, 1, 1, 0, 7, 5, 0, 5, 3, 6, 8, 1, 5, 7, 3, 2, 6, 1, 0, 5, 4, 8, 4, 6, 1, 1, 6, 6, 6, 5, 3, 7, 1, 9, 0, 2, 5, 4, 6, 0, 2, 0, 0, 3, 9, 4, 0, 7, 6, 0, 3, 1, 3, 2, 6, 5, 0, 1, 8, 9, 3, 6, 6, 9, 9, 9, 2, 2, 1, 0, 1, 2, 1, 4, 6, 4, 8, 0, 8, 2, 0, 2, 4, 6, 3, 3, 8, 6, 8, 1, 1, 3, 3, 2, 2, 8, 6, 7, 1, 1, 7, 8, 5, 1, 6, 1, 7, 7, 5, 0, 2, 6, 6, 1, 1, 9, 7, 8, 9, 7, 2, 7, 5, 8, 5, 8, 3, 0, 7, 3, 2, 4, 2, 1, 9, 8, 1, 2, 8, 0, 2, 1, 9, 3, 6, 0, 7, 1, 0, 2, 0, 7, 3, 7, 5, 2, 4, 0, 0, 4, 6, 4, 2, 0, 1, 3, 5, 8, 3, 5, 3, 6, 1, 9, 8, 8, 9, 2, 1, 7, 6, 8, 6, 9, 1, 4, 1, 6, 2, 1, 2, 7, 7, 4, 0, 0, 7, 6, 7, 6, 2, 7, 7, 3, 5, 0, 7, 5, 4, 6, 9, 3, 5, 1, 4, 1, 5, 4, 2, 5, 6, 6, 2, 3, 2, 4, 7, 5, 9, 5, 3, 8, 4, 2, 5, 5, 8, 6, 7, 7, 4, 4, 4, 3, 0, 2, 2, 5, 9, 4, 4, 7, 2, 8, 4, 2, 3, 4, 3, 2, 3, 6, 0, 4, 8, 8, 5, 1, 5, 0, 0, 2, 1, 4, 0, 5, 2, 2, 2, 1, 0, 3, 8, 0, 7, 6, 5, 8, 8, 0, 1, 8, 9, 1, 7, 2, 7, 9, 5, 7, 7, 1, 1, 6, 2, 6, 3, 5, 8, 3, 4, 4, 5, 1, 9, 9, 2, 1, 2, 6, 4, 4, 9, 3, 9, 9, 7, 8, 1, 2, 5, 5, 2, 5, 0, 2, 2, 9, 8, 8, 0, 1, 9, 5, 7, 7, 5, 6, 6, 5, 0, 4, 9, 8, 7, 1, 6, 9, 4, 1, 6, 8, 7, 2, 7, 4, 7, 5, 7, 1, 9, 7, 0, 1, 3, 3, 5, 9, 1, 8, 7, 8, 2, 6, 7, 7, 0, 8, 5, 2, 3, 0, 2, 1, 9, 2, 8, 5, 4, 5, 7, 4, 8, 3, 4, 4, 8, 6, 8, 9, 9, 2, 7, 6, 0, 7, 1, 8, 0, 9, 0, 3, 7, 4, 3, 7, 3, 9, 5, 8, 5, 3, 6, 9, 7, 3, 3, 8, 8, 1, 6, 1, 7, 0, 4, 1, 7, 3, 2, 4, 4, 2, 9, 4, 8, 0, 0, 6, 4, 9, 6, 1, 6, 2, 7, 9, 2, 6, 8, 0, 6, 0, 8, 1, 5, 4, 0, 1, 2, 5, 9, 1, 5, 1, 8, 8, 6, 7, 4, 7, 3, 3, 8, 1, 3, 8, 2, 6, 9, 2, 4, 7, 9, 6, 8, 9, 0, 2, 8, 3, 1, 6, 4, 0, 7, 7, 8, 9, 9, 5, 8, 7, 1, 2, 4, 1, 9, 8, 7, 3, 1, 3, 3, 8, 2, 6, 9, 0, 2, 0, 8, 1, 2, 6, 9, 3, 0, 7, 5, 8, 1, 8, 0, 1, 3, 3, 4, 9, 0, 1, 5, 5, 3, 9, 5, 9, 4, 2, 1, 3, 4, 1, 5, 3, 4, 0, 5, 4, 5, 8, 8, 2, 7, 3, 6, 9, 6, 8, 9, 0, 2, 8, 5, 2, 6, 1, 9, 2, 7, 2, 3, 1, 2, 9, 4, 8, 1, 0, 8, 3, 2, 5, 3, 1, 1, 7, 7, 6, 4, 7, 0, 0, 2, 2, 8, 8, 4, 2, 7, 8, 8, 4, 1, 1, 7, 5, 2, 1, 0, 2, 2, 1, 1, 7, 8, 3, 3, 2, 1, 1, 9, 8, 8, 4, 9, 3, 5, 0, 1, 3, 9, 9, 9, 0, 7, 4, 1, 9, 8, 2, 4, 8, 8, 8, 0, 1, 0, 1, 1, 6, 9, 6, 2, 8, 0, 6, 0, 8, 1, 3, 6, 8, 2, 5, 9, 1, 9, 8, 0, 4, 7, 6, 4, 1, 3, 7, 6, 0, 9, 0, 4, 7, 2, 9, 0, 1, 8, 9, 5, 5, 8, 9, 0, 8, 6, 0, 1, 2, 0, 2, 3, 1, 3, 1, 8, 7, 7, 3, 8, 9, 6, 3, 7, 9, 4, 9, 0, 5, 8, 3, 3, 9, 4, 3, 8, 2, 0, 5, 5, 3, 1, 8, 7, 6, 1, 8, 6, 0, 4, 4, 5, 2, 3, 8, 7, 1, 2, 6, 9, 9, 0, 7, 5, 4, 2, 7, 5, 1, 0, 4, 3, 4, 5, 4, 7, 7, 1, 2, 1, 3, 9, 8, 4, 3, 1, 7, 5, 0, 0, 0, 5, 8, 0, 6, 8, 7, 3, 1, 5, 0, 4, 1, 7, 1, 9, 0, 2, 9, 4, 8, 5, 6, 6, 0, 5, 5, 3, 0, 3, 8, 8, 9, 9, 2, 2, 7, 4, 3, 2, 9, 4, 7, 0, 8, 6, 7, 4, 4, 0, 1, 8, 9, 2, 6, 2, 5, 2, 5, 0, 7, 3, 0, 1, 6, 4, 8, 2, 2, 1, 4, 2, 2, 0, 4, 1, 0, 0, 7, 9, 8, 1, 0, 0, 7, 9, 5, 5, 0, 7, 1, 3, 1, 8, 2, 3, 3, 9, 1, 0, 6, 4, 4, 2, 3, 1, 6, 1, 2, 5, 2, 1, 7, 9, 1, 4, 2, 0, 8, 1, 4, 1, 7, 7, 4, 1, 0, 8, 1, 4, 0, 7, 5, 0, 0, 0, 2, 2, 4, 7, 4, 9, 0, 8, 8, 0, 6, 4, 3, 0, 6, 0, 3, 7, 8, 6, 1, 9, 3, 8, 0, 4, 9, 3, 4, 2, 0, 4, 6, 7, 8, 7, 4, 8, 3, 3, 2, 2, 9, 2, 3, 5, 6, 8, 2, 6, 6, 0, 9, 0, 2, 8, 6, 3, 3, 5, 3, 0, 1, 8, 2, 2, 5, 7, 9, 2, 1, 5, 4, 3, 7, 0, 3, 7, 3, 6, 2, 2, 9, 1, 6, 4, 1, 7, 5, 5, 6, 0, 9, 9, 0, 8, 6, 7, 6, 1, 7, 2, 7, 2, 2, 7, 6, 5, 0, 3, 9, 9, 9, 8, 0, 4, 6, 8, 2, 7, 6, 4, 3, 0, 2, 9, 0, 5, 1, 5, 2, 3, 5, 3, 3, 7, 7, 3, 3, 0, 2, 1, 5, 2, 6, 3, 1, 4, 3, 0, 0, 8, 7, 1, 9, 0, 8, 4, 3, 5, 6, 8, 9, 5, 6, 7, 3, 8, 0, 5, 0, 2, 9, 7, 1, 5, 9, 2, 6, 3, 1, 8, 6, 7, 8, 2, 4, 7, 5, 2, 4, 7, 8, 7, 5, 6, 6, 2, 5, 1, 8, 8, 2, 1, 0, 4, 8, 9, 4, 9, 1, 6, 5, 3, 4, 0, 8, 9, 0, 1, 7, 5, 7, 0, 4, 4, 2, 8, 8, 9, 7, 1, 1, 1, 6, 5, 3, 0, 9, 1, 8, 2, 7, 4, 5, 4, 5, 6, 8, 2, 5, 6, 8, 0, 0, 8, 0, 2, 1, 2, 6, 0, 0, 0, 8, 0, 2, 5, 3, 1, 1, 0, 1, 9, 9, 4, 8, 0, 3, 2, 1, 1, 0, 9, 3, 4, 3, 5, 7, 4, 7, 4, 6, 2, 1, 1, 5, 2, 9, 9, 6, 7, 7, 2, 8, 9, 8, 5, 1, 7, 9, 8, 2, 8, 2, 1, 2, 7, 3, 1, 6, 8, 9, 7, 3, 9, 3, 0, 9, 6, 6, 1, 2, 1, 6, 9, 3, 3, 1, 6, 6, 2, 7, 8, 3, 2, 7, 1, 7, 6, 4, 9, 1, 1, 8, 9, 6, 7, 9, 0, 2, 8, 6, 1, 9, 1, 2, 8, 4, 1, 6, 8, 8, 3, 2, 2, 5, 2, 0, 5, 2, 1, 8, 1, 0, 2, 3, 3, 9, 9, 7, 1, 1, 1, 0, 3, 4, 5, 9, 7, 4, 6, 3, 7, 4, 5, 5, 7, 2, 7, 7, 7, 8, 0, 6, 9, 2, 3, 1, 9, 9, 8, 3, 9, 9, 1, 2, 7, 9, 2, 0, 9, 2, 9, 5, 8, 6, 1, 3, 2, 9, 4, 6, 0, 6, 4, 9, 1, 0, 6, 6, 9, 8, 4, 5, 0, 1, 1, 6, 0, 8, 7, 9, 3, 7, 4, 8, 0, 1, 4, 2, 8, 5, 1, 0, 7, 7, 5, 4, 6, 5, 4, 0, 7, 5, 0, 1, 6, 8, 4, 5, 5, 3, 3, 7, 2, 8, 6, 2, 2, 0, 3, 9, 2, 8, 2, 9, 0, 7, 6, 6, 3, 6, 7, 0, 2, 4, 8, 6]\n",
            "       0\n",
            "0      9\n",
            "1      5\n",
            "2      2\n",
            "3      1\n",
            "4      8\n",
            "...   ..\n",
            "19995  0\n",
            "19996  2\n",
            "19997  4\n",
            "19998  8\n",
            "19999  6\n",
            "\n",
            "[20000 rows x 1 columns]\n"
          ]
        }
      ]
    }
  ]
}